{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbUyOvFdxFQl"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.x\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUxb56B_h6py"
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cuOyvyRmjJyQ"
   },
   "outputs": [],
   "source": [
    "# import keras_contrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D_ResNet50 : Source (https://github.com/JihongJu/keras-resnet3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "oJU6AzM_uJEO"
   },
   "outputs": [],
   "source": [
    "\"\"\"A vanilla 3D resnet implementation.\n",
    "Based on Raghavendra Kotikalapudi's 2D implementation\n",
    "keras-resnet (See https://github.com/raghakot/keras-resnet.)\n",
    "\"\"\"\n",
    "from __future__ import (\n",
    "    absolute_import,\n",
    "    division,\n",
    "    print_function,\n",
    "    unicode_literals\n",
    ")\n",
    "import six\n",
    "from math import ceil\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    Conv3D,\n",
    "    AveragePooling3D,\n",
    "    MaxPooling3D\n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block (by @raghakot).\"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu3D(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\n",
    "        \"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n",
    "                                                l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv3D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, kernel_initializer=kernel_initializer,\n",
    "                      padding=padding,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv3d(**conv_params):\n",
    "    \"\"\"Helper to build a  BN -> relu -> conv3d block.\"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\",\n",
    "                                                \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n",
    "                                                l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv3D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, kernel_initializer=kernel_initializer,\n",
    "                      padding=padding,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut3d(input, residual):\n",
    "    \"\"\"3D shortcut to match input and residual and merges them with \"sum\".\"\"\"\n",
    "    stride_dim1 = ceil(input._keras_shape[DIM1_AXIS] \\\n",
    "        / residual._keras_shape[DIM1_AXIS])\n",
    "    stride_dim2 = ceil(input._keras_shape[DIM2_AXIS] \\\n",
    "        / residual._keras_shape[DIM2_AXIS])\n",
    "    stride_dim3 = ceil(input._keras_shape[DIM3_AXIS] \\\n",
    "        / residual._keras_shape[DIM3_AXIS])\n",
    "    equal_channels = residual._keras_shape[CHANNEL_AXIS] \\\n",
    "        == input._keras_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 \\\n",
    "            or not equal_channels:\n",
    "        shortcut = Conv3D(\n",
    "            filters=residual._keras_shape[CHANNEL_AXIS],\n",
    "            kernel_size=(1, 1, 1),\n",
    "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
    "            kernel_initializer=\"he_normal\", padding=\"valid\",\n",
    "            kernel_regularizer=l2(1e-4)\n",
    "            )(input)\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block3d(block_function, filters, kernel_regularizer, repetitions,\n",
    "                      is_first_layer=False):\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            strides = (1, 1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                strides = (2, 2, 2)\n",
    "            input = block_function(filters=filters, strides=strides,\n",
    "                                   kernel_regularizer=kernel_regularizer,\n",
    "                                   is_first_block_of_first_layer=(\n",
    "                                       is_first_layer and i == 0)\n",
    "                                   )(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
    "                is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 X 3 convolution blocks. Extended from raghakot's 2D impl.\"\"\"\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n",
    "                           strides=strides, padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=kernel_regularizer\n",
    "                           )(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv3d(filters=filters,\n",
    "                                    kernel_size=(3, 3, 3),\n",
    "                                    strides=strides,\n",
    "                                    kernel_regularizer=kernel_regularizer\n",
    "                                    )(input)\n",
    "\n",
    "        residual = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n",
    "                                   kernel_regularizer=kernel_regularizer\n",
    "                                   )(conv1)\n",
    "        return _shortcut3d(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
    "               is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 X 3 convolution blocks. Extended from raghakot's 2D impl.\"\"\"\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv3D(filters=filters, kernel_size=(1, 1, 1),\n",
    "                              strides=strides, padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=kernel_regularizer\n",
    "                              )(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv3d(filters=filters, kernel_size=(1, 1, 1),\n",
    "                                       strides=strides,\n",
    "                                       kernel_regularizer=kernel_regularizer\n",
    "                                       )(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n",
    "                                   kernel_regularizer=kernel_regularizer\n",
    "                                   )(conv_1_1)\n",
    "        residual = _bn_relu_conv3d(filters=filters * 4, kernel_size=(1, 1, 1),\n",
    "                                   kernel_regularizer=kernel_regularizer\n",
    "                                   )(conv_3_3)\n",
    "\n",
    "        return _shortcut3d(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_data_format():\n",
    "    global DIM1_AXIS\n",
    "    global DIM2_AXIS\n",
    "    global DIM3_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        DIM1_AXIS = 1\n",
    "        DIM2_AXIS = 2\n",
    "        DIM3_AXIS = 3\n",
    "        CHANNEL_AXIS = 4\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        DIM1_AXIS = 2\n",
    "        DIM2_AXIS = 3\n",
    "        DIM3_AXIS = 4\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class Resnet3DBuilder(object):\n",
    "    \"\"\"ResNet3D.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions, reg_factor):\n",
    "        \"\"\"Instantiate a vanilla ResNet3D keras model.\n",
    "        # Arguments\n",
    "            input_shape: Tuple of input shape in the format\n",
    "            (conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'\n",
    "            (filter, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th'\n",
    "            num_outputs: The number of outputs at the final softmax layer\n",
    "            block_fn: Unit block to use {'basic_block', 'bottlenack_block'}\n",
    "            repetitions: Repetitions of unit blocks\n",
    "        # Returns\n",
    "            model: a 3D ResNet model that takes a 5D tensor (volumetric images\n",
    "            in batch) as input and returns a 1D vector (prediction) as output.\n",
    "        \"\"\"\n",
    "        _handle_data_format()\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\"Input shape should be a tuple \"\n",
    "                             \"(conv_dim1, conv_dim2, conv_dim3, channels) \"\n",
    "                             \"for tensorflow as backend or \"\n",
    "                             \"(channels, conv_dim1, conv_dim2, conv_dim3) \"\n",
    "                             \"for theano as backend\")\n",
    "\n",
    "        block_fn = _get_block(block_fn)\n",
    "        input = Input(shape=input_shape)\n",
    "        # first conv\n",
    "        conv1 = _conv_bn_relu3D(filters=64, kernel_size=(7, 7, 7),\n",
    "                                strides=(2, 2, 2),\n",
    "                                kernel_regularizer=l2(reg_factor)\n",
    "                                )(input)\n",
    "        pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2),\n",
    "                             padding=\"same\")(conv1)\n",
    "\n",
    "        # repeat blocks\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block3d(block_fn, filters=filters,\n",
    "                                      kernel_regularizer=l2(reg_factor),\n",
    "                                      repetitions=r, is_first_layer=(i == 0)\n",
    "                                      )(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # last activation\n",
    "        block_output = _bn_relu(block)\n",
    "\n",
    "        # average poll and classification\n",
    "        pool2 = AveragePooling3D(pool_size=(block._keras_shape[DIM1_AXIS],\n",
    "                                            block._keras_shape[DIM2_AXIS],\n",
    "                                            block._keras_shape[DIM3_AXIS]),\n",
    "                                 strides=(1, 1, 1))(block_output)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        if num_outputs > 1:\n",
    "            dense = Dense(units=num_outputs,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          activation=\"softmax\",\n",
    "                          kernel_regularizer=l2(reg_factor))(flatten1)\n",
    "        else:\n",
    "            dense = Dense(units=num_outputs,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          activation=\"sigmoid\",\n",
    "                          kernel_regularizer=l2(reg_factor))(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 18.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, basic_block,\n",
    "                                     [2, 2, 2, 2], reg_factor=reg_factor)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 34.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, basic_block,\n",
    "                                     [3, 4, 6, 3], reg_factor=reg_factor)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 50.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
    "                                     [3, 4, 6, 3], reg_factor=reg_factor)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 101.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
    "                                     [3, 4, 23, 3], reg_factor=reg_factor)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs, reg_factor=1e-4):\n",
    "        \"\"\"Build resnet 152.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
    "                                     [3, 8, 36, 3], reg_factor=reg_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install video generator library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWO0jx8oyrQH"
   },
   "outputs": [],
   "source": [
    "!pip install keras-video-generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call 3D_Resnet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTpp21VuwSlN"
   },
   "outputs": [],
   "source": [
    "i3d = Resnet3DBuilder.build_resnet_50(input_shape = (16, 224, 224, 3), num_outputs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZq73MgNxBm4"
   },
   "outputs": [],
   "source": [
    "i3d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess method for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdjYCIuLz96E"
   },
   "outputs": [],
   "source": [
    "def get_random_crop(image, crop_x, crop_y, crop_height, crop_width):\n",
    "\n",
    "\n",
    "\n",
    "    crop = image[crop_y: crop_y + crop_height, crop_x: crop_x + crop_width]\n",
    "\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess method for val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICQMUKDqDDce"
   },
   "outputs": [],
   "source": [
    "def crop_center(img, new_size):\n",
    "    y, x, c = img.shape\n",
    "    (cropx, cropy) = new_size\n",
    "    startx = x // 2 - (cropx // 2)\n",
    "    starty = y // 2 - (cropy // 2)\n",
    "    return img[starty:starty + cropy, startx:startx + cropx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom video generator for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NIFD5M2uyPwt"
   },
   "outputs": [],
   "source": [
    "from keras_video import VideoFrameGenerator\n",
    "from math import floor\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "\n",
    "class VideoFrameGenerator_RGB(VideoFrameGenerator):\n",
    "    def _get_frames(self, video, nbframe, shape, force_no_headers=False):\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        total_frames = self.count_frames(cap, video, force_no_headers)\n",
    "        frame_step = int(np.random.randint(total_frames-nbframe, size=1)) # 시작 프레임 랜덤으로 정의\n",
    "        # TODO: fix that, a tiny video can have a frame_step that is\n",
    "        # under 1\n",
    "        frame_step = max(1, frame_step)\n",
    "        frames = []\n",
    "        frame_i = 0\n",
    "        crop_width = 224\n",
    "        crop_height = 224\n",
    "        max_x = shape[1] - crop_width\n",
    "        max_y = shape[0] - crop_height\n",
    "\n",
    "        crop_x = np.random.randint(0, max_x)\n",
    "        crop_y = np.random.randint(0, max_y)\n",
    "        while True:\n",
    "            grabbed, frame = cap.read()\n",
    "            if not grabbed:\n",
    "                break\n",
    "\n",
    "            frame_i += 1\n",
    "            if frame_i >= frame_step: # 랜덤으로 정의된 값보다 크면\n",
    "                # resize\n",
    "                frame = cv2.resize(frame, shape)  ## 256, 256으로 리사이징\n",
    "                                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) ## 모델에 넣기 위해 RGB 채널로 변경\n",
    "                \n",
    "                #to np\n",
    "                frame = img_to_array(frame) \n",
    "                \n",
    "                frame = get_random_crop(frame, crop_x, crop_y,  crop_width, crop_height) ## 데이터 증강을 위한 랜덤 크롭\n",
    "                frame = (frame - frame.mean()) / frame.std()\n",
    "                \n",
    "                frames.append(frame)\n",
    "            if len(frames) == nbframe:\n",
    "                break\n",
    "        cap.release()\n",
    "\n",
    "        if not force_no_headers and len(frames) != nbframe:\n",
    "            # There is a problem here\n",
    "            # That means that frame count in header is wrong or broken,\n",
    "            # so we need to force the full read of video to get the right\n",
    "            # frame counter\n",
    "            return self._get_frames(\n",
    "                    video,\n",
    "                    nbframe,\n",
    "                    shape,\n",
    "                    force_no_headers=True)\n",
    "\n",
    "        if force_no_headers and len(frames) != nbframe:\n",
    "            # and if we really couldn't find the real frame counter\n",
    "            # so we return None. Sorry, nothing can be done...\n",
    "            log.error(\"Frame count is not OK for video %s, \"\n",
    "                      \"%d total, %d extracted\" % (\n",
    "                        video, total_frames, len(frames)))\n",
    "            return None\n",
    "        return np.array(frames)\n",
    "    \n",
    "    def __getitem__(self, index): ## 데이터 증강 후 0~255 사이의 값이기 때문에 255로 나눠줌\n",
    "        classes = self.classes\n",
    "        shape = self.target_shape\n",
    "        nbframe = self.nbframe\n",
    "\n",
    "        labels = []\n",
    "        images = []\n",
    "\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        transformation = None\n",
    "\n",
    "        for i in indexes:\n",
    "            # prepare a transformation if provided\n",
    "            if self.transformation is not None:\n",
    "                transformation = self._random_trans[i]\n",
    "\n",
    "            video = self.files[i]\n",
    "            classname = self._get_classname(video)\n",
    "\n",
    "            # create a label array and set 1 to the right column\n",
    "            label = np.zeros(len(classes))\n",
    "            col = classes.index(classname)\n",
    "            label[col] = 1.\n",
    "\n",
    "\n",
    "            frames = self._get_frames(\n",
    "                video,\n",
    "                nbframe,\n",
    "                shape,\n",
    "                force_no_headers=not self.use_video_header)\n",
    "            if frames is None:\n",
    "                # avoid failure, nevermind that video...\n",
    "                continue\n",
    "\n",
    "            # apply transformation\n",
    "            if transformation is not None:\n",
    "                frames = [self.transformation.apply_transform(\n",
    "                    frame, transformation) for frame in frames]\n",
    "\n",
    "            # add the sequence in batch\n",
    "            images.append(frames)\n",
    "            labels.append(label)\n",
    "\n",
    "        return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0H2LpC2ARVU"
   },
   "source": [
    "## define custom video generator for val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKloDMOwymms"
   },
   "outputs": [],
   "source": [
    "from keras_video import VideoFrameGenerator\n",
    "from math import floor\n",
    "import cv2\n",
    "import numpy as np\n",
    "class VideoFrameGenerator_RGB_val(VideoFrameGenerator):\n",
    "    def _get_frames(self, video, nbframe, shape, force_no_headers=False):\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        total_frames = self.count_frames(cap, video, force_no_headers)\n",
    "        frame_step = int(np.random.randint(total_frames-nbframe, size=1))  # 시작 프레임 랜덤으로 정의\n",
    "        # TODO: fix that, a tiny video can have a frame_step that is\n",
    "        # under 1\n",
    "        frame_step = max(1, frame_step)\n",
    "        frames = []\n",
    "        frame_i = 0\n",
    "\n",
    "        while True:\n",
    "            grabbed, frame = cap.read()\n",
    "            if not grabbed:\n",
    "                break\n",
    "\n",
    "            frame_i += 1\n",
    "            if frame_i >= frame_step:  # 랜덤으로 정의된 값보다 크면\n",
    "                # resize\n",
    "                frame = cv2.resize(frame, shape)  ## 224, 224으로 리사이징\n",
    "                frame = crop_center(frame, (224, 224))\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  ## 모델에 넣기 위해 RGB 채널로 변경\n",
    "                \n",
    "                #to np\n",
    "                frame = img_to_array(frame)\n",
    "                frame = (frame - frame.mean()) / frame.std()\n",
    "                \n",
    "                frames.append(frame)\n",
    "            if len(frames) == nbframe:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if not force_no_headers and len(frames) != nbframe:\n",
    "            # There is a problem here\n",
    "            # That means that frame count in header is wrong or broken,\n",
    "            # so we need to force the full read of video to get the right\n",
    "            # frame counter\n",
    "            return self._get_frames(\n",
    "                    video,\n",
    "                    nbframe,\n",
    "                    shape,\n",
    "                    force_no_headers=True)\n",
    "\n",
    "        if force_no_headers and len(frames) != nbframe:\n",
    "            # and if we really couldn't find the real frame counter\n",
    "            # so we return None. Sorry, nothing can be done...\n",
    "            log.error(\"Frame count is not OK for video %s, \"\n",
    "                      \"%d total, %d extracted\" % (\n",
    "                        video, total_frames, len(frames)))\n",
    "            return None\n",
    "\n",
    "        return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## call custom video generator and image augmentation for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2kOmg7zzIcc"
   },
   "outputs": [],
   "source": [
    "from keras_video import VideoFrameGenerator\n",
    "import os\n",
    "import glob\n",
    "import keras\n",
    "NBFRAME = 16\n",
    "classes = [i.split(os.path.sep)[-1] for i in glob.glob('drive/My Drive/Dataset/final_project/Image/*')]\n",
    "classes.sort()\n",
    "# some global params\n",
    "SIZE = (256, 256)\n",
    "CHANNELS = 1\n",
    "BS = 32\n",
    "# pattern to get videos and classes\n",
    "glob_pattern='./drive/My Drive/Dataset/final_project/Image/{classname}/*.mp4'\n",
    "\n",
    "# for data augmentation\n",
    "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "    # zoom_range=.2,\n",
    "    # brightness_range=[0.7, 1.3],\n",
    "    # rotation_range = 20,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2\n",
    "    )\n",
    "# Create video frame generator\n",
    "train = VideoFrameGenerator_RGB(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## call custom video generator for val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJtspomhzV4Y"
   },
   "outputs": [],
   "source": [
    "glob_pattern='./drive/My Drive/Dataset/final_project/Val/{classname}/*.mp4'\n",
    "\n",
    "valid = VideoFrameGenerator_RGB_val(\n",
    "    rescale=1./255,\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME, \n",
    "    batch_size=16,\n",
    "    target_shape=(256, 256),\n",
    "    nb_channel=CHANNELS,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define recall method for evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WW13TbrhzcmZ"
   },
   "outputs": [],
   "source": [
    "def single_class_recall(interesting_class_id):\n",
    "    def recall(y_true, y_pred):\n",
    "        class_id_true = keras.backend.argmax(y_true, axis=-1)\n",
    "        class_id_pred = keras.backend.argmax(y_pred, axis=-1)\n",
    "        recall_mask = keras.backend.cast(keras.backend.equal(class_id_true, interesting_class_id), 'int32')\n",
    "        class_recall_tensor = keras.backend.cast(keras.backend.equal(class_id_true, class_id_pred), 'int32') * recall_mask\n",
    "        class_recall = keras.backend.cast(keras.backend.sum(class_recall_tensor), 'float32') / keras.backend.cast(keras.backend.maximum(keras.backend.sum(recall_mask), 1), 'float32')\n",
    "        return class_recall\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZLo0_kbzgdw"
   },
   "outputs": [],
   "source": [
    "i3d.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=0.1, momentum=0.9, decay=0.9)\n",
    "            , metrics=['accuracy', single_class_recall(0), single_class_recall(1), single_class_recall(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKuMMqualj1V"
   },
   "source": [
    "# Tensorboard 사용 (For colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z34-MENpleXQ"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = '/tmp/log'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiHOVsi0lfa-"
   },
   "outputs": [],
   "source": [
    "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "! unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em1amuIWlhGd"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VF21tu_al8sH"
   },
   "outputs": [],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define callback method for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4_42YLqDzhBJ"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20000\n",
    "callbacks = [\n",
    "    # keras.callbacks.ReduceLROnPlateau(verbose=1, \n",
    "    #                                   monitor='loss',# 모니터 기준 설정 (loss) \n",
    "    #                                   patience=10, # 10 회 Epoch동안 loss가 감소하지 않으면\n",
    "    #                                   factor=0.9, #learning_rate*factor로 learning rate 수정 \n",
    "    #                                   min_lr=1e-4 #최소 0.00001\n",
    "    #                                   ),\n",
    "    keras.callbacks.ModelCheckpoint('drive/My Drive/Dataset/final_project/i3d_resnet_RGB.hdf5', \n",
    "                                              monitor='loss', \n",
    "                                              verbose=1, save_best_only=True, save_weights_only=True, \n",
    "                                              mode='auto', period=1),\n",
    "    # keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, update_freq='epoch', write_images=True),\n",
    "#     keras.callbacks.EarlyStopping(monitor='val_loss',  # 모니터 기준 설정 (loss) \n",
    "#                               patience=100,         # 100회 Epoch동안 개선되지 않는다면 종료\n",
    "#                              ),\n",
    "    keras.callbacks.TensorBoard(log_dir='/tmp/log', histogram_freq=0, write_graph=True, update_freq='epoch', write_images=True),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJik69GTzrmv"
   },
   "outputs": [],
   "source": [
    "i3d.fit_generator(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMnyAUtYOrejFdKgjYh7ssM",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1SAeB3kK75iepNjw8nD-Z_Rw1LnWpBtPO",
   "name": "i3d_keras_resnet.ipynb의 사본",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1YvvCOrT1aj0LIn_tg8gvV_N8ON07dLPT",
     "timestamp": 1587000133325
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
