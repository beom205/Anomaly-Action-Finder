{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select tensorFlow version for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F4E_YklrUUid",
    "outputId": "96fb418b-cf52-44db-8bc0-5fe1fe360dbb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A_r2LxQiFH_E",
    "outputId": "583ffd7a-9995-420e-f824-8d8eda62aabc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9DJTPsuFH_I"
   },
   "source": [
    "## 인셉션 블록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2a4bOi0iFH_L"
   },
   "source": [
    "![](https://user-images.githubusercontent.com/31475037/61274906-b1931080-a7e7-11e9-9756-1542abc9758f.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HTiokUOVFH_M"
   },
   "source": [
    "![](https://user-images.githubusercontent.com/31475037/61275666-637f0c80-a7e9-11e9-817b-3543c5fd328c.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88NN498_FH_M"
   },
   "source": [
    "## i3d 네트워크 선언 Source : (https://github.com/dlpbc/keras-kinetics-i3d/blob/master/i3d_inception.py)\n",
    "## Colab에서의 편의성을 위해 코드 자체를 가지고 다님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0jw3VJtFH_N"
   },
   "outputs": [],
   "source": [
    "\"\"\"Inception-v1 Inflated 3D ConvNet used for Kinetics CVPR paper.\n",
    " \n",
    "The model is introduced in:\n",
    " \n",
    "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\n",
    "Joao Carreira, Andrew Zisserman\n",
    "https://arxiv.org/abs/1705.07750v1\n",
    "\"\"\"\n",
    "        \n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import MaxPooling3D\n",
    "from keras.layers import AveragePooling3D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import GlobalAveragePooling3D\n",
    "\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "\n",
    "WEIGHTS_NAME = ['rgb_kinetics_only', 'flow_kinetics_only', 'rgb_imagenet_and_kinetics', 'flow_imagenet_and_kinetics']\n",
    "\n",
    "# path to pretrained models with top (classification layer)\n",
    "WEIGHTS_PATH = {\n",
    "    'rgb_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels.h5',\n",
    "    'flow_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels.h5',\n",
    "    'rgb_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels.h5',\n",
    "    'flow_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels.h5'\n",
    "}\n",
    "\n",
    "# path to pretrained models with no top (no classification layer)\n",
    "WEIGHTS_PATH_NO_TOP = {\n",
    "    'rgb_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels_no_top.h5',\n",
    "    'flow_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels_no_top.h5',\n",
    "    'rgb_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels_no_top.h5',\n",
    "    'flow_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels_no_top.h5'\n",
    "}\n",
    "\n",
    "\n",
    "def _obtain_input_shape(input_shape,\n",
    "                        default_frame_size,\n",
    "                        min_frame_size,\n",
    "                        default_num_frames,\n",
    "                        min_num_frames,\n",
    "                        data_format,\n",
    "                        require_flatten,\n",
    "                        weights=None):\n",
    "    \"\"\"Internal utility to compute/validate the model's input shape.\n",
    "    (Adapted from `keras/applications/imagenet_utils.py`)\n",
    "    # Arguments\n",
    "        input_shape: either None (will return the default network input shape),\n",
    "            or a user-provided shape to be validated.\n",
    "        default_frame_size: default input frames(images) width/height for the model.\n",
    "        min_frame_size: minimum input frames(images) width/height accepted by the model.\n",
    "        default_num_frames: default input number of frames(images) for the model.\n",
    "        min_num_frames: minimum input number of frames accepted by the model.\n",
    "        data_format: image data format to use.\n",
    "        require_flatten: whether the model is expected to\n",
    "            be linked to a classifier via a Flatten layer.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or 'kinetics_only' (pre-training on Kinetics dataset).\n",
    "            or 'imagenet_and_kinetics' (pre-training on ImageNet and Kinetics datasets).\n",
    "            If weights='kinetics_only' or weights=='imagenet_and_kinetics' then\n",
    "            input channels must be equal to 3.\n",
    "    # Returns\n",
    "        An integer shape tuple (may include None entries).\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument values.\n",
    "    \"\"\"\n",
    "    if weights != 'kinetics_only' and weights != 'imagenet_and_kinetics' and input_shape and len(input_shape) == 4:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape[0] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[0]) + ' input channels.')\n",
    "            default_shape = (input_shape[0], default_num_frames, default_frame_size, default_frame_size)\n",
    "        else:\n",
    "            if input_shape[-1] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with ' +\n",
    "                    str(input_shape[-1]) + ' input channels.')\n",
    "            default_shape = (default_num_frames, default_frame_size, default_frame_size, input_shape[-1])\n",
    "    else:\n",
    "        if data_format == 'channels_first':\n",
    "            default_shape = (3, default_num_frames, default_frame_size, default_frame_size)\n",
    "        else:\n",
    "            default_shape = (default_num_frames, default_frame_size, default_frame_size, 3)\n",
    "    if (weights == 'kinetics_only' or weights == 'imagenet_and_kinetics') and require_flatten:\n",
    "        if input_shape is not None:\n",
    "            if input_shape != default_shape:\n",
    "                raise ValueError('When setting`include_top=True` '\n",
    "                                 'and loading `imagenet` weights, '\n",
    "                                 '`input_shape` should be ' +\n",
    "                                 str(default_shape) + '.')\n",
    "        return default_shape\n",
    "\n",
    "    if input_shape:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 4:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of four integers.')\n",
    "                if input_shape[0] != 3 and (weights == 'kinetics_only' or weights == 'imagenet_and_kinetics'):\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "\n",
    "                if input_shape[1] is not None and input_shape[1] < min_num_frames:\n",
    "                    raise ValueError('Input number of frames must be at least ' +\n",
    "                                     str(min_num_frames) + '; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "\n",
    "                if ((input_shape[2] is not None and input_shape[2] < min_frame_size) or\n",
    "                   (input_shape[3] is not None and input_shape[3] < min_frame_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_frame_size) + 'x' + str(min_frame_size) + '; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "        else:\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 4:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of four integers.')\n",
    "                if input_shape[-1] != 3 and (weights == 'kinetics_only' or weights == 'imagenet_and_kinetics'):\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "\n",
    "                if input_shape[0] is not None and input_shape[0] < min_num_frames:\n",
    "                    raise ValueError('Input number of frames must be at least ' +\n",
    "                                     str(min_num_frames) + '; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "\n",
    "                if ((input_shape[1] is not None and input_shape[1] < min_frame_size) or\n",
    "                   (input_shape[2] is not None and input_shape[2] < min_frame_size)):\n",
    "                    raise ValueError('Input size must be at least ' +\n",
    "                                     str(min_frame_size) + 'x' + str(min_frame_size) + '; got '\n",
    "                                     '`input_shape=' + str(input_shape) + '`')\n",
    "    else:\n",
    "        if require_flatten:\n",
    "            input_shape = default_shape\n",
    "        else:\n",
    "            if data_format == 'channels_first':\n",
    "                input_shape = (3, None, None, None)\n",
    "            else:\n",
    "                input_shape = (None, None, None, 3)\n",
    "    if require_flatten:\n",
    "        if None in input_shape:\n",
    "            raise ValueError('If `include_top` is True, '\n",
    "                             'you should specify a static `input_shape`. '\n",
    "                             'Got `input_shape=' + str(input_shape) + '`')\n",
    "    return input_shape\n",
    "\n",
    "\n",
    "def conv3d_bn(x,\n",
    "              filters,\n",
    "              num_frames,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              padding='same',\n",
    "              strides=(1, 1, 1),\n",
    "              use_bias = False,\n",
    "              use_activation_fn = True,\n",
    "              use_bn = True,\n",
    "              name=None):\n",
    "    \"\"\"Utility function to apply conv3d + BN.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: filters in `Conv3D`.\n",
    "        num_frames: frames (time depth) of the convolution kernel.\n",
    "        num_row: height of the convolution kernel.\n",
    "        num_col: width of the convolution kernel.\n",
    "        padding: padding mode in `Conv3D`.\n",
    "        strides: strides in `Conv3D`.\n",
    "        use_bias: use bias or not  \n",
    "        use_activation_fn: use an activation function or not.\n",
    "        use_bn: use batch normalization or not.\n",
    "        name: name of the ops; will become `name + '_conv'`\n",
    "            for the convolution and `name + '_bn'` for the\n",
    "            batch norm layer.\n",
    "    # Returns\n",
    "        Output tensor after applying `Conv3D` and `BatchNormalization`.\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "\n",
    "    x = Conv3D(\n",
    "        filters, (num_frames, num_row, num_col),\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "        name=conv_name)(x)\n",
    "\n",
    "    if use_bn:\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            bn_axis = 1\n",
    "        else:\n",
    "            bn_axis = 4\n",
    "        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "\n",
    "    if use_activation_fn:\n",
    "        x = Activation('relu', name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def Inception_Inflated3d(include_top=True,\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                input_shape=None,\n",
    "                dropout_prob=0.0,\n",
    "                endpoint_logit=True,\n",
    "                classes=400):\n",
    "    \"\"\"Instantiates the Inflated 3D Inception v1 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on Kinetics. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format='channels_last'` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    Note that the default input frame(image) size for this model is 224x224.\n",
    "    # Arguments\n",
    "        include_top: whether to include the the classification \n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or 'kinetics_only' (pre-training on Kinetics dataset only).\n",
    "            or 'imagenet_and_kinetics' (pre-training on ImageNet and Kinetics datasets).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(NUM_FRAMES, 224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(NUM_FRAMES, 3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels.\n",
    "            NUM_FRAMES should be no smaller than 8. The authors used 64\n",
    "            frames per example for training and testing on kinetics dataset\n",
    "            Also, Width and height should be no smaller than 32.\n",
    "            E.g. `(64, 150, 150, 3)` would be one valid value.\n",
    "        dropout_prob: optional, dropout probability applied in dropout layer\n",
    "            after global average pooling layer. \n",
    "            0.0 means no dropout is applied, 1.0 means dropout is applied to all features.\n",
    "            Note: Since Dropout is applied just before the classification\n",
    "            layer, it is only useful when `include_top` is set to True.\n",
    "        endpoint_logit: (boolean) optional. If True, the model's forward pass\n",
    "            will end at producing logits. Otherwise, softmax is applied after producing\n",
    "            the logits to produce the class probabilities prediction. Setting this parameter \n",
    "            to True is particularly useful when you want to combine results of rgb model\n",
    "            and optical flow model.\n",
    "            - `True` end model forward pass at logit output\n",
    "            - `False` go further after logit to produce softmax predictions\n",
    "            Note: This parameter is only useful when `include_top` is set to True.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if not (weights in WEIGHTS_NAME or weights is None or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or %s' % \n",
    "                         str(WEIGHTS_NAME) + ' ' \n",
    "                         'or a valid path to a file containing `weights` values')\n",
    "\n",
    "    if weights in WEIGHTS_NAME and include_top and classes != 400:\n",
    "        raise ValueError('If using `weights` as one of these %s, with `include_top`'\n",
    "                         ' as true, `classes` should be 400' % str(WEIGHTS_NAME))\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(\n",
    "        input_shape,\n",
    "        default_frame_size=224, \n",
    "        min_frame_size=32, \n",
    "        default_num_frames=64,\n",
    "        min_num_frames=8,\n",
    "        data_format=K.image_data_format(),\n",
    "        require_flatten=include_top,\n",
    "        weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = 4\n",
    "\n",
    "    # Downsampling via convolution (spatial and temporal)\n",
    "    x = conv3d_bn(img_input, 64, 7, 7, 7, strides=(2, 2, 2), padding='same', name='Conv3d_1a_7x7')\n",
    "\n",
    "    # Downsampling (spatial only)\n",
    "    x = MaxPooling3D((1, 3, 3), strides=(1, 2, 2), padding='same', name='MaxPool2d_2a_3x3')(x)\n",
    "    x = conv3d_bn(x, 64, 1, 1, 1, strides=(1, 1, 1), padding='same', name='Conv3d_2b_1x1')\n",
    "    x = conv3d_bn(x, 192, 3, 3, 3, strides=(1, 1, 1), padding='same', name='Conv3d_2c_3x3')\n",
    "\n",
    "    # Downsampling (spatial only)\n",
    "    x = MaxPooling3D((1, 3, 3), strides=(1, 2, 2), padding='same', name='MaxPool2d_3a_3x3')(x)\n",
    "\n",
    "    # Mixed 3b\n",
    "    branch_0 = conv3d_bn(x, 64, 1, 1, 1, padding='same', name='Conv3d_3b_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 96, 1, 1, 1, padding='same', name='Conv3d_3b_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 128, 3, 3, 3, padding='same', name='Conv3d_3b_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 16, 1, 1, 1, padding='same', name='Conv3d_3b_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 32, 3, 3, 3, padding='same', name='Conv3d_3b_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_3b_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 32, 1, 1, 1, padding='same', name='Conv3d_3b_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_3b')\n",
    "\n",
    "    # Mixed 3c\n",
    "    branch_0 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_3c_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_3c_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 192, 3, 3, 3, padding='same', name='Conv3d_3c_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_3c_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 96, 3, 3, 3, padding='same', name='Conv3d_3c_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_3c_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_3c_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_3c')\n",
    "\n",
    "\n",
    "    # Downsampling (spatial and temporal)\n",
    "    x = MaxPooling3D((3, 3, 3), strides=(2, 2, 2), padding='same', name='MaxPool2d_4a_3x3')(x)\n",
    "\n",
    "    # Mixed 4b\n",
    "    branch_0 = conv3d_bn(x, 192, 1, 1, 1, padding='same', name='Conv3d_4b_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 96, 1, 1, 1, padding='same', name='Conv3d_4b_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 208, 3, 3, 3, padding='same', name='Conv3d_4b_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 16, 1, 1, 1, padding='same', name='Conv3d_4b_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 48, 3, 3, 3, padding='same', name='Conv3d_4b_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4b_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4b_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_4b')\n",
    "\n",
    "    # Mixed 4c\n",
    "    branch_0 = conv3d_bn(x, 160, 1, 1, 1, padding='same', name='Conv3d_4c_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 112, 1, 1, 1, padding='same', name='Conv3d_4c_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 224, 3, 3, 3, padding='same', name='Conv3d_4c_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 24, 1, 1, 1, padding='same', name='Conv3d_4c_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4c_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4c_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4c_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_4c')\n",
    "\n",
    "    # Mixed 4d\n",
    "    branch_0 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_4d_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_4d_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 256, 3, 3, 3, padding='same', name='Conv3d_4d_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 24, 1, 1, 1, padding='same', name='Conv3d_4d_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4d_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4d_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4d_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_4d')\n",
    "\n",
    "    # Mixed 4e\n",
    "    branch_0 = conv3d_bn(x, 112, 1, 1, 1, padding='same', name='Conv3d_4e_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 144, 1, 1, 1, padding='same', name='Conv3d_4e_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 288, 3, 3, 3, padding='same', name='Conv3d_4e_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_4e_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4e_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4e_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4e_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_4e')\n",
    "\n",
    "    # Mixed 4f\n",
    "    branch_0 = conv3d_bn(x, 256, 1, 1, 1, padding='same', name='Conv3d_4f_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 160, 1, 1, 1, padding='same', name='Conv3d_4f_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 320, 3, 3, 3, padding='same', name='Conv3d_4f_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_4f_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_4f_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4f_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_4f_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_4f')\n",
    "\n",
    "\n",
    "    # Downsampling (spatial and temporal)\n",
    "    x = MaxPooling3D((2, 2, 2), strides=(2, 2, 2), padding='same', name='MaxPool2d_5a_2x2')(x)\n",
    "\n",
    "    # Mixed 5b\n",
    "    branch_0 = conv3d_bn(x, 256, 1, 1, 1, padding='same', name='Conv3d_5b_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 160, 1, 1, 1, padding='same', name='Conv3d_5b_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 320, 3, 3, 3, padding='same', name='Conv3d_5b_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_5b_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_5b_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_5b_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_5b_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_5b')\n",
    "\n",
    "    # Mixed 5c\n",
    "    branch_0 = conv3d_bn(x, 384, 1, 1, 1, padding='same', name='Conv3d_5c_0a_1x1')\n",
    "\n",
    "    branch_1 = conv3d_bn(x, 192, 1, 1, 1, padding='same', name='Conv3d_5c_1a_1x1')\n",
    "    branch_1 = conv3d_bn(branch_1, 384, 3, 3, 3, padding='same', name='Conv3d_5c_1b_3x3')\n",
    "\n",
    "    branch_2 = conv3d_bn(x, 48, 1, 1, 1, padding='same', name='Conv3d_5c_2a_1x1')\n",
    "    branch_2 = conv3d_bn(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_5c_2b_3x3')\n",
    "\n",
    "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_5c_3a_3x3')(x)\n",
    "    branch_3 = conv3d_bn(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_5c_3b_1x1')\n",
    "\n",
    "    x = layers.concatenate(\n",
    "        [branch_0, branch_1, branch_2, branch_3],\n",
    "        axis=channel_axis,\n",
    "        name='Mixed_5c')\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = AveragePooling3D((2, 7, 7), strides=(1, 1, 1), padding='valid', name='global_avg_pool')(x)\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "\n",
    "        x = conv3d_bn(x, classes, 1, 1, 1, padding='same', \n",
    "                use_bias=True, use_activation_fn=False, use_bn=False, name='Conv3d_6a_1x1')\n",
    " \n",
    "        num_frames_remaining = int(x.shape[1])\n",
    "        x = Reshape((num_frames_remaining, classes))(x)\n",
    "\n",
    "        # logits (raw scores for each class)\n",
    "        x = Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n",
    "                   output_shape=lambda s: (s[0], s[2]))(x)\n",
    "\n",
    "        if not endpoint_logit:\n",
    "            x = Activation('softmax', name='prediction')(x)\n",
    "    else:\n",
    "        h = int(x.shape[2])\n",
    "        w = int(x.shape[3])\n",
    "        x = AveragePooling3D((2, h, w), strides=(1, 1, 1), padding='valid', name='global_avg_pool')(x)\n",
    "\n",
    "\n",
    "\n",
    "    inputs = img_input\n",
    "    # create model\n",
    "    model = Model(inputs, x, name='i3d_inception')\n",
    "\n",
    "    # load weights\n",
    "    if weights in WEIGHTS_NAME:\n",
    "        if weights == WEIGHTS_NAME[0]:   # rgb_kinetics_only\n",
    "            if include_top:\n",
    "                weights_url = WEIGHTS_PATH['rgb_kinetics_only']\n",
    "                model_name = 'i3d_inception_rgb_kinetics_only.h5'\n",
    "            else:\n",
    "                weights_url = WEIGHTS_PATH_NO_TOP['rgb_kinetics_only']\n",
    "                model_name = 'i3d_inception_rgb_kinetics_only_no_top.h5'\n",
    "\n",
    "        elif weights == WEIGHTS_NAME[1]: # flow_kinetics_only\n",
    "            if include_top:\n",
    "                weights_url = WEIGHTS_PATH['flow_kinetics_only']\n",
    "                model_name = 'i3d_inception_flow_kinetics_only.h5'\n",
    "            else:\n",
    "                weights_url = WEIGHTS_PATH_NO_TOP['flow_kinetics_only']\n",
    "                model_name = 'i3d_inception_flow_kinetics_only_no_top.h5'\n",
    "\n",
    "        elif weights == WEIGHTS_NAME[2]: # rgb_imagenet_and_kinetics\n",
    "            if include_top:\n",
    "                weights_url = WEIGHTS_PATH['rgb_imagenet_and_kinetics']\n",
    "                model_name = 'i3d_inception_rgb_imagenet_and_kinetics.h5'\n",
    "            else:\n",
    "                weights_url = WEIGHTS_PATH_NO_TOP['rgb_imagenet_and_kinetics']\n",
    "                model_name = 'i3d_inception_rgb_imagenet_and_kinetics_no_top.h5'\n",
    "\n",
    "        elif weights == WEIGHTS_NAME[3]: # flow_imagenet_and_kinetics\n",
    "            if include_top:\n",
    "                weights_url = WEIGHTS_PATH['flow_imagenet_and_kinetics']\n",
    "                model_name = 'i3d_inception_flow_imagenet_and_kinetics.h5'\n",
    "            else:\n",
    "                weights_url = WEIGHTS_PATH_NO_TOP['flow_imagenet_and_kinetics']\n",
    "                model_name = 'i3d_inception_flow_imagenet_and_kinetics_no_top.h5'\n",
    "\n",
    "        downloaded_weights_path = get_file(model_name, weights_url, cache_subdir='models')\n",
    "        model.load_weights(downloaded_weights_path)\n",
    "\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
    "            warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                          'are using the Theano '\n",
    "                          'image data format convention '\n",
    "                          '(`image_data_format=\"channels_first\"`). '\n",
    "                          'For best performance, set '\n",
    "                          '`image_data_format=\"channels_last\"` in '\n",
    "                          'your keras config '\n",
    "                          'at ~/.keras/keras.json.')\n",
    "\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0X5ZYK3kFH_P"
   },
   "source": [
    "## 네트워크 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "bIluOoniFH_P",
    "outputId": "3c121495-97b2-4835-b5e5-67f74a2d9454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels_no_top.h5\n",
      "49602560/49595336 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "\n",
    "a = keras.layers.Input(shape=(16, 224, 224, 3))\n",
    "\n",
    "i3d = Inception_Inflated3d(include_top=False,\n",
    "            weights=\"rgb_imagenet_and_kinetics\",\n",
    "            input_tensor=a,\n",
    "            input_shape=None,\n",
    "            dropout_prob=0.5,\n",
    "            endpoint_logit=True,\n",
    "            classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vIM2XbOJUdjN",
    "outputId": "fc9afd02-5a83-42ba-8145-2d3ff32fac42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"i3d_inception\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1_rgb (InputLayer)        (None, 16, 224, 224, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_1a_7x7_conv_rgb (Conv3D) (None, 8, 112, 112,  65856       input_1_rgb[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_1a_7x7_bn_rgb (BatchNorm (None, 8, 112, 112,  192         Conv3d_1a_7x7_conv_rgb[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_1a_7x7_rgb (Activation)  (None, 8, 112, 112,  0           Conv3d_1a_7x7_bn_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_2a_3x3_rgb (MaxPoolin (None, 8, 56, 56, 64 0           Conv3d_1a_7x7_rgb[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2b_1x1_conv_rgb (Conv3D) (None, 8, 56, 56, 64 4096        MaxPool2d_2a_3x3_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2b_1x1_bn_rgb (BatchNorm (None, 8, 56, 56, 64 192         Conv3d_2b_1x1_conv_rgb[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2b_1x1_rgb (Activation)  (None, 8, 56, 56, 64 0           Conv3d_2b_1x1_bn_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2c_3x3_conv_rgb (Conv3D) (None, 8, 56, 56, 19 331776      Conv3d_2b_1x1_rgb[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2c_3x3_bn_rgb (BatchNorm (None, 8, 56, 56, 19 576         Conv3d_2c_3x3_conv_rgb[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2c_3x3_rgb (Activation)  (None, 8, 56, 56, 19 0           Conv3d_2c_3x3_bn_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_3a_3x3_rgb (MaxPoolin (None, 8, 28, 28, 19 0           Conv3d_2c_3x3_rgb[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1a_1x1_conv_rgb (Conv (None, 8, 28, 28, 96 18432       MaxPool2d_3a_3x3_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2a_1x1_conv_rgb (Conv (None, 8, 28, 28, 16 3072        MaxPool2d_3a_3x3_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1a_1x1_bn_rgb (BatchN (None, 8, 28, 28, 96 288         Conv3d_3b_1a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2a_1x1_bn_rgb (BatchN (None, 8, 28, 28, 16 48          Conv3d_3b_2a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1a_1x1_rgb (Activatio (None, 8, 28, 28, 96 0           Conv3d_3b_1a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2a_1x1_rgb (Activatio (None, 8, 28, 28, 16 0           Conv3d_3b_2a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_3b_3a_3x3_rgb (MaxPoo (None, 8, 28, 28, 19 0           MaxPool2d_3a_3x3_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_0a_1x1_conv_rgb (Conv (None, 8, 28, 28, 64 12288       MaxPool2d_3a_3x3_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1b_3x3_conv_rgb (Conv (None, 8, 28, 28, 12 331776      Conv3d_3b_1a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2b_3x3_conv_rgb (Conv (None, 8, 28, 28, 32 13824       Conv3d_3b_2a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_3b_1x1_conv_rgb (Conv (None, 8, 28, 28, 32 6144        MaxPool2d_3b_3a_3x3_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_0a_1x1_bn_rgb (BatchN (None, 8, 28, 28, 64 192         Conv3d_3b_0a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1b_3x3_bn_rgb (BatchN (None, 8, 28, 28, 12 384         Conv3d_3b_1b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2b_3x3_bn_rgb (BatchN (None, 8, 28, 28, 32 96          Conv3d_3b_2b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_3b_1x1_bn_rgb (BatchN (None, 8, 28, 28, 32 96          Conv3d_3b_3b_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_0a_1x1_rgb (Activatio (None, 8, 28, 28, 64 0           Conv3d_3b_0a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1b_3x3_rgb (Activatio (None, 8, 28, 28, 12 0           Conv3d_3b_1b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2b_3x3_rgb (Activatio (None, 8, 28, 28, 32 0           Conv3d_3b_2b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_3b_1x1_rgb (Activatio (None, 8, 28, 28, 32 0           Conv3d_3b_3b_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_3b_rgb (Concatenate)      (None, 8, 28, 28, 25 0           Conv3d_3b_0a_1x1_rgb[0][0]       \n",
      "                                                                 Conv3d_3b_1b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_3b_2b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_3b_3b_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1a_1x1_conv_rgb (Conv (None, 8, 28, 28, 12 32768       Mixed_3b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2a_1x1_conv_rgb (Conv (None, 8, 28, 28, 32 8192        Mixed_3b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1a_1x1_bn_rgb (BatchN (None, 8, 28, 28, 12 384         Conv3d_3c_1a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2a_1x1_bn_rgb (BatchN (None, 8, 28, 28, 32 96          Conv3d_3c_2a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1a_1x1_rgb (Activatio (None, 8, 28, 28, 12 0           Conv3d_3c_1a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2a_1x1_rgb (Activatio (None, 8, 28, 28, 32 0           Conv3d_3c_2a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_3c_3a_3x3_rgb (MaxPoo (None, 8, 28, 28, 25 0           Mixed_3b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_0a_1x1_conv_rgb (Conv (None, 8, 28, 28, 12 32768       Mixed_3b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1b_3x3_conv_rgb (Conv (None, 8, 28, 28, 19 663552      Conv3d_3c_1a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2b_3x3_conv_rgb (Conv (None, 8, 28, 28, 96 82944       Conv3d_3c_2a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_3b_1x1_conv_rgb (Conv (None, 8, 28, 28, 64 16384       MaxPool2d_3c_3a_3x3_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_0a_1x1_bn_rgb (BatchN (None, 8, 28, 28, 12 384         Conv3d_3c_0a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1b_3x3_bn_rgb (BatchN (None, 8, 28, 28, 19 576         Conv3d_3c_1b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2b_3x3_bn_rgb (BatchN (None, 8, 28, 28, 96 288         Conv3d_3c_2b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_3b_1x1_bn_rgb (BatchN (None, 8, 28, 28, 64 192         Conv3d_3c_3b_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_0a_1x1_rgb (Activatio (None, 8, 28, 28, 12 0           Conv3d_3c_0a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1b_3x3_rgb (Activatio (None, 8, 28, 28, 19 0           Conv3d_3c_1b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2b_3x3_rgb (Activatio (None, 8, 28, 28, 96 0           Conv3d_3c_2b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_3b_1x1_rgb (Activatio (None, 8, 28, 28, 64 0           Conv3d_3c_3b_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_3c_rgb (Concatenate)      (None, 8, 28, 28, 48 0           Conv3d_3c_0a_1x1_rgb[0][0]       \n",
      "                                                                 Conv3d_3c_1b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_3c_2b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_3c_3b_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4a_3x3_rgb (MaxPoolin (None, 4, 14, 14, 48 0           Mixed_3c_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1a_1x1_conv_rgb (Conv (None, 4, 14, 14, 96 46080       MaxPool2d_4a_3x3_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2a_1x1_conv_rgb (Conv (None, 4, 14, 14, 16 7680        MaxPool2d_4a_3x3_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 96 288         Conv3d_4b_1a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 16 48          Conv3d_4b_2a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1a_1x1_rgb (Activatio (None, 4, 14, 14, 96 0           Conv3d_4b_1a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2a_1x1_rgb (Activatio (None, 4, 14, 14, 16 0           Conv3d_4b_2a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4b_3a_3x3_rgb (MaxPoo (None, 4, 14, 14, 48 0           MaxPool2d_4a_3x3_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_0a_1x1_conv_rgb (Conv (None, 4, 14, 14, 19 92160       MaxPool2d_4a_3x3_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1b_3x3_conv_rgb (Conv (None, 4, 14, 14, 20 539136      Conv3d_4b_1a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2b_3x3_conv_rgb (Conv (None, 4, 14, 14, 48 20736       Conv3d_4b_2a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_3b_1x1_conv_rgb (Conv (None, 4, 14, 14, 64 30720       MaxPool2d_4b_3a_3x3_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_0a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 19 576         Conv3d_4b_0a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1b_3x3_bn_rgb (BatchN (None, 4, 14, 14, 20 624         Conv3d_4b_1b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2b_3x3_bn_rgb (BatchN (None, 4, 14, 14, 48 144         Conv3d_4b_2b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_3b_1x1_bn_rgb (BatchN (None, 4, 14, 14, 64 192         Conv3d_4b_3b_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_0a_1x1_rgb (Activatio (None, 4, 14, 14, 19 0           Conv3d_4b_0a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1b_3x3_rgb (Activatio (None, 4, 14, 14, 20 0           Conv3d_4b_1b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2b_3x3_rgb (Activatio (None, 4, 14, 14, 48 0           Conv3d_4b_2b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_3b_1x1_rgb (Activatio (None, 4, 14, 14, 64 0           Conv3d_4b_3b_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_4b_rgb (Concatenate)      (None, 4, 14, 14, 51 0           Conv3d_4b_0a_1x1_rgb[0][0]       \n",
      "                                                                 Conv3d_4b_1b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_4b_2b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_4b_3b_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1a_1x1_conv_rgb (Conv (None, 4, 14, 14, 11 57344       Mixed_4b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2a_1x1_conv_rgb (Conv (None, 4, 14, 14, 24 12288       Mixed_4b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 11 336         Conv3d_4c_1a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 24 72          Conv3d_4c_2a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1a_1x1_rgb (Activatio (None, 4, 14, 14, 11 0           Conv3d_4c_1a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2a_1x1_rgb (Activatio (None, 4, 14, 14, 24 0           Conv3d_4c_2a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4c_3a_3x3_rgb (MaxPoo (None, 4, 14, 14, 51 0           Mixed_4b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_0a_1x1_conv_rgb (Conv (None, 4, 14, 14, 16 81920       Mixed_4b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1b_3x3_conv_rgb (Conv (None, 4, 14, 14, 22 677376      Conv3d_4c_1a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2b_3x3_conv_rgb (Conv (None, 4, 14, 14, 64 41472       Conv3d_4c_2a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_3b_1x1_conv_rgb (Conv (None, 4, 14, 14, 64 32768       MaxPool2d_4c_3a_3x3_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_0a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 16 480         Conv3d_4c_0a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1b_3x3_bn_rgb (BatchN (None, 4, 14, 14, 22 672         Conv3d_4c_1b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2b_3x3_bn_rgb (BatchN (None, 4, 14, 14, 64 192         Conv3d_4c_2b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_3b_1x1_bn_rgb (BatchN (None, 4, 14, 14, 64 192         Conv3d_4c_3b_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_0a_1x1_rgb (Activatio (None, 4, 14, 14, 16 0           Conv3d_4c_0a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1b_3x3_rgb (Activatio (None, 4, 14, 14, 22 0           Conv3d_4c_1b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2b_3x3_rgb (Activatio (None, 4, 14, 14, 64 0           Conv3d_4c_2b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_3b_1x1_rgb (Activatio (None, 4, 14, 14, 64 0           Conv3d_4c_3b_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_4c_rgb (Concatenate)      (None, 4, 14, 14, 51 0           Conv3d_4c_0a_1x1_rgb[0][0]       \n",
      "                                                                 Conv3d_4c_1b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_4c_2b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_4c_3b_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1a_1x1_conv_rgb (Conv (None, 4, 14, 14, 12 65536       Mixed_4c_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2a_1x1_conv_rgb (Conv (None, 4, 14, 14, 24 12288       Mixed_4c_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 12 384         Conv3d_4d_1a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 24 72          Conv3d_4d_2a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1a_1x1_rgb (Activatio (None, 4, 14, 14, 12 0           Conv3d_4d_1a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2a_1x1_rgb (Activatio (None, 4, 14, 14, 24 0           Conv3d_4d_2a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4d_3a_3x3_rgb (MaxPoo (None, 4, 14, 14, 51 0           Mixed_4c_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_0a_1x1_conv_rgb (Conv (None, 4, 14, 14, 12 65536       Mixed_4c_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1b_3x3_conv_rgb (Conv (None, 4, 14, 14, 25 884736      Conv3d_4d_1a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2b_3x3_conv_rgb (Conv (None, 4, 14, 14, 64 41472       Conv3d_4d_2a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_3b_1x1_conv_rgb (Conv (None, 4, 14, 14, 64 32768       MaxPool2d_4d_3a_3x3_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_0a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 12 384         Conv3d_4d_0a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1b_3x3_bn_rgb (BatchN (None, 4, 14, 14, 25 768         Conv3d_4d_1b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2b_3x3_bn_rgb (BatchN (None, 4, 14, 14, 64 192         Conv3d_4d_2b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_3b_1x1_bn_rgb (BatchN (None, 4, 14, 14, 64 192         Conv3d_4d_3b_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_0a_1x1_rgb (Activatio (None, 4, 14, 14, 12 0           Conv3d_4d_0a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1b_3x3_rgb (Activatio (None, 4, 14, 14, 25 0           Conv3d_4d_1b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2b_3x3_rgb (Activatio (None, 4, 14, 14, 64 0           Conv3d_4d_2b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_3b_1x1_rgb (Activatio (None, 4, 14, 14, 64 0           Conv3d_4d_3b_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_4d_rgb (Concatenate)      (None, 4, 14, 14, 51 0           Conv3d_4d_0a_1x1_rgb[0][0]       \n",
      "                                                                 Conv3d_4d_1b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_4d_2b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_4d_3b_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1a_1x1_conv_rgb (Conv (None, 4, 14, 14, 14 73728       Mixed_4d_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2a_1x1_conv_rgb (Conv (None, 4, 14, 14, 32 16384       Mixed_4d_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 14 432         Conv3d_4e_1a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 32 96          Conv3d_4e_2a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1a_1x1_rgb (Activatio (None, 4, 14, 14, 14 0           Conv3d_4e_1a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2a_1x1_rgb (Activatio (None, 4, 14, 14, 32 0           Conv3d_4e_2a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4e_3a_3x3_rgb (MaxPoo (None, 4, 14, 14, 51 0           Mixed_4d_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_0a_1x1_conv_rgb (Conv (None, 4, 14, 14, 11 57344       Mixed_4d_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1b_3x3_conv_rgb (Conv (None, 4, 14, 14, 28 1119744     Conv3d_4e_1a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2b_3x3_conv_rgb (Conv (None, 4, 14, 14, 64 55296       Conv3d_4e_2a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_3b_1x1_conv_rgb (Conv (None, 4, 14, 14, 64 32768       MaxPool2d_4e_3a_3x3_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_0a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 11 336         Conv3d_4e_0a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1b_3x3_bn_rgb (BatchN (None, 4, 14, 14, 28 864         Conv3d_4e_1b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2b_3x3_bn_rgb (BatchN (None, 4, 14, 14, 64 192         Conv3d_4e_2b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_3b_1x1_bn_rgb (BatchN (None, 4, 14, 14, 64 192         Conv3d_4e_3b_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_0a_1x1_rgb (Activatio (None, 4, 14, 14, 11 0           Conv3d_4e_0a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1b_3x3_rgb (Activatio (None, 4, 14, 14, 28 0           Conv3d_4e_1b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2b_3x3_rgb (Activatio (None, 4, 14, 14, 64 0           Conv3d_4e_2b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_3b_1x1_rgb (Activatio (None, 4, 14, 14, 64 0           Conv3d_4e_3b_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_4e_rgb (Concatenate)      (None, 4, 14, 14, 52 0           Conv3d_4e_0a_1x1_rgb[0][0]       \n",
      "                                                                 Conv3d_4e_1b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_4e_2b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_4e_3b_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1a_1x1_conv_rgb (Conv (None, 4, 14, 14, 16 84480       Mixed_4e_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2a_1x1_conv_rgb (Conv (None, 4, 14, 14, 32 16896       Mixed_4e_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 16 480         Conv3d_4f_1a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 32 96          Conv3d_4f_2a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1a_1x1_rgb (Activatio (None, 4, 14, 14, 16 0           Conv3d_4f_1a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2a_1x1_rgb (Activatio (None, 4, 14, 14, 32 0           Conv3d_4f_2a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4f_3a_3x3_rgb (MaxPoo (None, 4, 14, 14, 52 0           Mixed_4e_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_0a_1x1_conv_rgb (Conv (None, 4, 14, 14, 25 135168      Mixed_4e_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1b_3x3_conv_rgb (Conv (None, 4, 14, 14, 32 1382400     Conv3d_4f_1a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2b_3x3_conv_rgb (Conv (None, 4, 14, 14, 12 110592      Conv3d_4f_2a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_3b_1x1_conv_rgb (Conv (None, 4, 14, 14, 12 67584       MaxPool2d_4f_3a_3x3_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_0a_1x1_bn_rgb (BatchN (None, 4, 14, 14, 25 768         Conv3d_4f_0a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1b_3x3_bn_rgb (BatchN (None, 4, 14, 14, 32 960         Conv3d_4f_1b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2b_3x3_bn_rgb (BatchN (None, 4, 14, 14, 12 384         Conv3d_4f_2b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_3b_1x1_bn_rgb (BatchN (None, 4, 14, 14, 12 384         Conv3d_4f_3b_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_0a_1x1_rgb (Activatio (None, 4, 14, 14, 25 0           Conv3d_4f_0a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1b_3x3_rgb (Activatio (None, 4, 14, 14, 32 0           Conv3d_4f_1b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2b_3x3_rgb (Activatio (None, 4, 14, 14, 12 0           Conv3d_4f_2b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_3b_1x1_rgb (Activatio (None, 4, 14, 14, 12 0           Conv3d_4f_3b_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_4f_rgb (Concatenate)      (None, 4, 14, 14, 83 0           Conv3d_4f_0a_1x1_rgb[0][0]       \n",
      "                                                                 Conv3d_4f_1b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_4f_2b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_4f_3b_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_5a_2x2_rgb (MaxPoolin (None, 2, 7, 7, 832) 0           Mixed_4f_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1a_1x1_conv_rgb (Conv (None, 2, 7, 7, 160) 133120      MaxPool2d_5a_2x2_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2a_1x1_conv_rgb (Conv (None, 2, 7, 7, 32)  26624       MaxPool2d_5a_2x2_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1a_1x1_bn_rgb (BatchN (None, 2, 7, 7, 160) 480         Conv3d_5b_1a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2a_1x1_bn_rgb (BatchN (None, 2, 7, 7, 32)  96          Conv3d_5b_2a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1a_1x1_rgb (Activatio (None, 2, 7, 7, 160) 0           Conv3d_5b_1a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2a_1x1_rgb (Activatio (None, 2, 7, 7, 32)  0           Conv3d_5b_2a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_5b_3a_3x3_rgb (MaxPoo (None, 2, 7, 7, 832) 0           MaxPool2d_5a_2x2_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_0a_1x1_conv_rgb (Conv (None, 2, 7, 7, 256) 212992      MaxPool2d_5a_2x2_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1b_3x3_conv_rgb (Conv (None, 2, 7, 7, 320) 1382400     Conv3d_5b_1a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2b_3x3_conv_rgb (Conv (None, 2, 7, 7, 128) 110592      Conv3d_5b_2a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_3b_1x1_conv_rgb (Conv (None, 2, 7, 7, 128) 106496      MaxPool2d_5b_3a_3x3_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_0a_1x1_bn_rgb (BatchN (None, 2, 7, 7, 256) 768         Conv3d_5b_0a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1b_3x3_bn_rgb (BatchN (None, 2, 7, 7, 320) 960         Conv3d_5b_1b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2b_3x3_bn_rgb (BatchN (None, 2, 7, 7, 128) 384         Conv3d_5b_2b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_3b_1x1_bn_rgb (BatchN (None, 2, 7, 7, 128) 384         Conv3d_5b_3b_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_0a_1x1_rgb (Activatio (None, 2, 7, 7, 256) 0           Conv3d_5b_0a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1b_3x3_rgb (Activatio (None, 2, 7, 7, 320) 0           Conv3d_5b_1b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2b_3x3_rgb (Activatio (None, 2, 7, 7, 128) 0           Conv3d_5b_2b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_3b_1x1_rgb (Activatio (None, 2, 7, 7, 128) 0           Conv3d_5b_3b_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_5b_rgb (Concatenate)      (None, 2, 7, 7, 832) 0           Conv3d_5b_0a_1x1_rgb[0][0]       \n",
      "                                                                 Conv3d_5b_1b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_5b_2b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_5b_3b_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1a_1x1_conv_rgb (Conv (None, 2, 7, 7, 192) 159744      Mixed_5b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2a_1x1_conv_rgb (Conv (None, 2, 7, 7, 48)  39936       Mixed_5b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1a_1x1_bn_rgb (BatchN (None, 2, 7, 7, 192) 576         Conv3d_5c_1a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2a_1x1_bn_rgb (BatchN (None, 2, 7, 7, 48)  144         Conv3d_5c_2a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1a_1x1_rgb (Activatio (None, 2, 7, 7, 192) 0           Conv3d_5c_1a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2a_1x1_rgb (Activatio (None, 2, 7, 7, 48)  0           Conv3d_5c_2a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_5c_3a_3x3_rgb (MaxPoo (None, 2, 7, 7, 832) 0           Mixed_5b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_0a_1x1_conv_rgb (Conv (None, 2, 7, 7, 384) 319488      Mixed_5b_rgb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1b_3x3_conv_rgb (Conv (None, 2, 7, 7, 384) 1990656     Conv3d_5c_1a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2b_3x3_conv_rgb (Conv (None, 2, 7, 7, 128) 165888      Conv3d_5c_2a_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_3b_1x1_conv_rgb (Conv (None, 2, 7, 7, 128) 106496      MaxPool2d_5c_3a_3x3_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_0a_1x1_bn_rgb (BatchN (None, 2, 7, 7, 384) 1152        Conv3d_5c_0a_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1b_3x3_bn_rgb (BatchN (None, 2, 7, 7, 384) 1152        Conv3d_5c_1b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2b_3x3_bn_rgb (BatchN (None, 2, 7, 7, 128) 384         Conv3d_5c_2b_3x3_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_3b_1x1_bn_rgb (BatchN (None, 2, 7, 7, 128) 384         Conv3d_5c_3b_1x1_conv_rgb[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_0a_1x1_rgb (Activatio (None, 2, 7, 7, 384) 0           Conv3d_5c_0a_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1b_3x3_rgb (Activatio (None, 2, 7, 7, 384) 0           Conv3d_5c_1b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2b_3x3_rgb (Activatio (None, 2, 7, 7, 128) 0           Conv3d_5c_2b_3x3_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_3b_1x1_rgb (Activatio (None, 2, 7, 7, 128) 0           Conv3d_5c_3b_1x1_bn_rgb[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_5c_rgb (Concatenate)      (None, 2, 7, 7, 1024 0           Conv3d_5c_0a_1x1_rgb[0][0]       \n",
      "                                                                 Conv3d_5c_1b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_5c_2b_3x3_rgb[0][0]       \n",
      "                                                                 Conv3d_5c_3b_1x1_rgb[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_avg_pool_rgb (AveragePoo (None, 1, 1, 1, 1024 0           Mixed_5c_rgb[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 12,294,544\n",
      "Trainable params: 12,279,984\n",
      "Non-trainable params: 14,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in i3d.layers:\n",
    "    layer.name = layer.name + str(\"_rgb\")\n",
    "i3d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7RPbG26FrEA"
   },
   "outputs": [],
   "source": [
    "net = keras.models.Sequential()\n",
    "net.add(i3d)\n",
    "net.add(keras.layers.Flatten())\n",
    "net.add(Dropout(0.5))\n",
    "net.add(Dense(3, activation=None ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "pos6XKDRFH_S",
    "outputId": "ba981080-1df8-4d47-ea8a-05424295eacc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "i3d_inception (Model)        (None, 1, 1, 1, 1024)     12294544  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 12,297,619\n",
      "Trainable params: 12,283,059\n",
      "Non-trainable params: 14,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JL3WJSKuFH_U"
   },
   "source": [
    "## 랜덤 크롭 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLRjWT4l_ccr"
   },
   "outputs": [],
   "source": [
    "def get_random_crop(image, crop_x, crop_y, crop_height, crop_width):\n",
    "\n",
    "    crop = image[crop_y: crop_y + crop_height, crop_x: crop_x + crop_width]\n",
    "\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umYBX7fpAMGR"
   },
   "outputs": [],
   "source": [
    "def crop_center(img, new_size):\n",
    "    y, x, c = img.shape\n",
    "    (cropx, cropy) = new_size\n",
    "    startx = x // 2 - (cropx // 2)\n",
    "    starty = y // 2 - (cropy // 2)\n",
    "    return img[starty:starty + cropy, startx:startx + cropx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxMJXkOCFH_a"
   },
   "source": [
    "## RGB 용 데이터 제네레이터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "X4UF8eZMAZfA",
    "outputId": "5273a90e-5b1e-4fe6-862f-bc51cc1e6087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-video-generators\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/98/ff550be6084b0537f1340783a6850a2f2b62b87273472a56c17ed84bcdb3/keras-video-generators-1.0.14.tar.gz\n",
      "Requirement already satisfied: keras>=2 in /usr/local/lib/python3.6/dist-packages (from keras-video-generators) (2.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-video-generators) (1.18.3)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from keras-video-generators) (4.1.2.30)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from keras-video-generators) (3.2.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-video-generators) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-video-generators) (3.13)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-video-generators) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-video-generators) (1.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-video-generators) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2->keras-video-generators) (1.12.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-video-generators) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-video-generators) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-video-generators) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-video-generators) (2.4.7)\n",
      "Building wheels for collected packages: keras-video-generators\n",
      "  Building wheel for keras-video-generators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-video-generators: filename=keras_video_generators-1.0.14-cp36-none-any.whl size=12883 sha256=e63fb7de915aaebc1c851adde5e0279c32709f198c889303c95603bfc97676dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/20/b7/76/8674d46fc4777c09e5aa7b065d4e356d90f12ec409a6144bbb\n",
      "Successfully built keras-video-generators\n",
      "Installing collected packages: keras-video-generators\n",
      "Successfully installed keras-video-generators-1.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-video-generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cytDCoPvFH_b"
   },
   "outputs": [],
   "source": [
    "from keras_video import VideoFrameGenerator\n",
    "from math import floor\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "\n",
    "class VideoFrameGenerator_RGB(VideoFrameGenerator):\n",
    "    def _get_frames(self, video, nbframe, shape, force_no_headers=False):\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        total_frames = self.count_frames(cap, video, force_no_headers)\n",
    "        frame_step = int(np.random.randint(total_frames-nbframe, size=1)) # 시작 프레임 랜덤으로 정의\n",
    "        # TODO: fix that, a tiny video can have a frame_step that is\n",
    "        # under 1\n",
    "        frame_step = max(1, frame_step)\n",
    "        frames = []\n",
    "        frame_i = 0\n",
    "        crop_width = 224\n",
    "        crop_height = 224\n",
    "        max_x = shape[1] - crop_width\n",
    "        max_y = shape[0] - crop_height\n",
    "\n",
    "        crop_x = np.random.randint(0, max_x)\n",
    "        crop_y = np.random.randint(0, max_y)\n",
    "        while True:\n",
    "            grabbed, frame = cap.read()\n",
    "            if not grabbed:\n",
    "                break\n",
    "\n",
    "            frame_i += 1\n",
    "            if frame_i >= frame_step: # 랜덤으로 정의된 값보다 크면\n",
    "                # resize\n",
    "                frame = cv2.resize(frame, shape)  ## 256, 256으로 리사이징\n",
    "                                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) ## 모델에 넣기 위해 RGB 채널로 변경\n",
    "                \n",
    "                #to np\n",
    "                frame = img_to_array(frame) \n",
    "                \n",
    "                frame = get_random_crop(frame, crop_x, crop_y,  crop_width, crop_height) ## 데이터 증강을 위한 랜덤 크롭\n",
    "                frame = (frame - frame.mean()) / frame.std()\n",
    "                \n",
    "                frames.append(frame)\n",
    "            if len(frames) == nbframe:\n",
    "                break\n",
    "        cap.release()\n",
    "\n",
    "        if not force_no_headers and len(frames) != nbframe:\n",
    "            # There is a problem here\n",
    "            # That means that frame count in header is wrong or broken,\n",
    "            # so we need to force the full read of video to get the right\n",
    "            # frame counter\n",
    "            return self._get_frames(\n",
    "                    video,\n",
    "                    nbframe,\n",
    "                    shape,\n",
    "                    force_no_headers=True)\n",
    "\n",
    "        if force_no_headers and len(frames) != nbframe:\n",
    "            # and if we really couldn't find the real frame counter\n",
    "            # so we return None. Sorry, nothing can be done...\n",
    "            log.error(\"Frame count is not OK for video %s, \"\n",
    "                      \"%d total, %d extracted\" % (\n",
    "                        video, total_frames, len(frames)))\n",
    "            return None\n",
    "        return np.array(frames)\n",
    "    \n",
    "    def __getitem__(self, index): ## 데이터 증강 후 0~255 사이의 값이기 때문에 255로 나눠줌\n",
    "        classes = self.classes\n",
    "        shape = self.target_shape\n",
    "        nbframe = self.nbframe\n",
    "\n",
    "        labels = []\n",
    "        images = []\n",
    "\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        transformation = None\n",
    "\n",
    "        for i in indexes:\n",
    "            # prepare a transformation if provided\n",
    "            if self.transformation is not None:\n",
    "                transformation = self._random_trans[i]\n",
    "\n",
    "            video = self.files[i]\n",
    "            classname = self._get_classname(video)\n",
    "\n",
    "            # create a label array and set 1 to the right column\n",
    "            label = np.zeros(len(classes))\n",
    "            col = classes.index(classname)\n",
    "            label[col] = 1.\n",
    "\n",
    "\n",
    "            frames = self._get_frames(\n",
    "                video,\n",
    "                nbframe,\n",
    "                shape,\n",
    "                force_no_headers=not self.use_video_header)\n",
    "            if frames is None:\n",
    "                # avoid failure, nevermind that video...\n",
    "                continue\n",
    "\n",
    "            # apply transformation\n",
    "            if transformation is not None:\n",
    "                frames = [self.transformation.apply_transform(\n",
    "                    frame, transformation) for frame in frames]\n",
    "\n",
    "            # add the sequence in batch\n",
    "            images.append(frames)\n",
    "            labels.append(label)\n",
    "\n",
    "        return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxmXh7ZTFH_d"
   },
   "outputs": [],
   "source": [
    "from keras_video import VideoFrameGenerator\n",
    "from math import floor\n",
    "import cv2\n",
    "import numpy as np\n",
    "class VideoFrameGenerator_RGB_val(VideoFrameGenerator):\n",
    "    def _get_frames(self, video, nbframe, shape, force_no_headers=False):\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        total_frames = self.count_frames(cap, video, force_no_headers)\n",
    "        frame_step = int(np.random.randint(total_frames-nbframe, size=1))  # 시작 프레임 랜덤으로 정의\n",
    "        # TODO: fix that, a tiny video can have a frame_step that is\n",
    "        # under 1\n",
    "        frame_step = max(1, frame_step)\n",
    "        frames = []\n",
    "        frame_i = 0\n",
    "\n",
    "        while True:\n",
    "            grabbed, frame = cap.read()\n",
    "            if not grabbed:\n",
    "                break\n",
    "\n",
    "            frame_i += 1\n",
    "            if frame_i >= frame_step:  # 랜덤으로 정의된 값보다 크면\n",
    "                # resize\n",
    "                frame = cv2.resize(frame, shape)  ## 224, 224으로 리사이징\n",
    "                frame = crop_center(frame, (224, 224))\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  ## 모델에 넣기 위해 RGB 채널로 변경\n",
    "                \n",
    "                #to np\n",
    "                frame = img_to_array(frame)\n",
    "                frame = (frame - frame.mean()) / frame.std()\n",
    "                \n",
    "                frames.append(frame)\n",
    "            if len(frames) == nbframe:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if not force_no_headers and len(frames) != nbframe:\n",
    "            # There is a problem here\n",
    "            # That means that frame count in header is wrong or broken,\n",
    "            # so we need to force the full read of video to get the right\n",
    "            # frame counter\n",
    "            return self._get_frames(\n",
    "                    video,\n",
    "                    nbframe,\n",
    "                    shape,\n",
    "                    force_no_headers=True)\n",
    "\n",
    "        if force_no_headers and len(frames) != nbframe:\n",
    "            # and if we really couldn't find the real frame counter\n",
    "            # so we return None. Sorry, nothing can be done...\n",
    "            log.error(\"Frame count is not OK for video %s, \"\n",
    "                      \"%d total, %d extracted\" % (\n",
    "                        video, total_frames, len(frames)))\n",
    "            return None\n",
    "\n",
    "        return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MHdWs4KCFH_p"
   },
   "source": [
    "## 훈련에 사용할 비디오 제네레이터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bcwj_M4VFH_p",
    "outputId": "14bf54ec-b02f-49fb-e574-c8944febb245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 3 classes for 573 files for train\n"
     ]
    }
   ],
   "source": [
    "from keras_video import VideoFrameGenerator\n",
    "import os\n",
    "import glob\n",
    "import keras\n",
    "\n",
    "classes = [i.split(os.path.sep)[-1] for i in glob.glob('Image/*')]\n",
    "classes.sort()\n",
    "# some global params\n",
    "SIZE = (256, 256)\n",
    "CHANNELS = 3\n",
    "NBFRAME = 16\n",
    "BS = 32\n",
    "# pattern to get videos and classes\n",
    "glob_pattern='Image/{classname}/*.mp4'\n",
    "\n",
    "# for data augmentation\n",
    "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "    # zoom_range=.2,\n",
    "    # brightness_range=[0.7, 1.3],\n",
    "    # rotation_range = 20,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2)\n",
    "# Create video frame generator\n",
    "train = VideoFrameGenerator_RGB(\n",
    "    rescale=1/255.,\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    transformation=None,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcdiGMcSzGaU"
   },
   "outputs": [],
   "source": [
    "X, y = train.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fBQbEAb9FH_r"
   },
   "source": [
    "## VAlidation에 사용할 데이터 제네레이터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uM-0hdQsFH_s",
    "outputId": "89f48fea-597c-40a1-f027-a43109034d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 3 classes for 37 files for train\n"
     ]
    }
   ],
   "source": [
    "glob_pattern='Val/{classname}/*.mp4'\n",
    "\n",
    "valid = VideoFrameGenerator_RGB_val(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME, \n",
    "    batch_size=16,\n",
    "    target_shape=(224, 224),\n",
    "    nb_channel=CHANNELS,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TiloeDhiFH_u"
   },
   "source": [
    "## 각 클래스에 대해서 recall 값 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6zn2q5dFH_u"
   },
   "outputs": [],
   "source": [
    "def single_class_recall(interesting_class_id):\n",
    "    def recall(y_true, y_pred):\n",
    "        class_id_true = keras.backend.argmax(y_true, axis=-1)\n",
    "        class_id_pred = keras.backend.argmax(y_pred, axis=-1)\n",
    "        recall_mask = keras.backend.cast(keras.backend.equal(class_id_true, interesting_class_id), 'int32')\n",
    "        class_recall_tensor = keras.backend.cast(keras.backend.equal(class_id_true, class_id_pred), 'int32') * recall_mask\n",
    "        class_recall = keras.backend.cast(keras.backend.sum(class_recall_tensor), 'float32') / keras.backend.cast(keras.backend.maximum(keras.backend.sum(recall_mask), 1), 'float32')\n",
    "        return class_recall\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCASAsw0OUHM"
   },
   "outputs": [],
   "source": [
    "def catego_crossentropy(y_actual, y_predicted):\n",
    "    y_predicted = keras.activations.softmax(y_predicted, axis=-1)\n",
    "    return keras.losses.categorical_crossentropy(y_actual, y_predicted, from_logits=False, label_smoothing=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nERQqL2rFH_x"
   },
   "source": [
    "## 모델 compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7_iK4UbFH_y"
   },
   "outputs": [],
   "source": [
    "net.compile(loss=catego_crossentropy,\n",
    "                optimizer=keras.optimizers.SGD(lr=0.1, momentum=0.9, decay=0.9)\n",
    "            , metrics=['accuracy', single_class_recall(0), single_class_recall(1), single_class_recall(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UyIH2N1FH_0"
   },
   "outputs": [],
   "source": [
    "net.load_weights(\"weights_i3d_RGB_v3.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코랩용 tensorboard 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1ndzeNfGszb"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = '/tmp/log'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "OQXvs4sIGxlj",
    "outputId": "cb649945-80eb-4736-bdbd-f91f3fbcc428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-28 00:06:24--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 34.196.154.11, 52.54.171.88, 3.227.142.238, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|34.196.154.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13773305 (13M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  13.13M  6.01MB/s    in 2.2s    \n",
      "\n",
      "2020-04-28 00:06:27 (6.01 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
      "\n",
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n"
     ]
    }
   ],
   "source": [
    "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "! unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDP6RGS9GzX-"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EjV9YGUIG0zw",
    "outputId": "b97829ac-3a43-4002-f648-fcf01fa13690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://b58c23fd.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cUXtqTe6FH_2"
   },
   "source": [
    "## 훈련을 위한 콜백 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8krqnC1HFH_3"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20000\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(verbose=1, \n",
    "                                      monitor='loss',# 모니터 기준 설정 (loss) \n",
    "                                      patience=10, # 10 회 Epoch동안 loss가 감소하지 않으면\n",
    "                                      factor=0.999, #learning_rate*factor로 learning rate 수정 \n",
    "                                      min_lr=1e-4 #최소 0.00001\n",
    "                                      ),\n",
    "    keras.callbacks.ModelCheckpoint('weights_i3d_RGB_no_softmax.hdf5', \n",
    "                                              monitor='loss', \n",
    "                                              verbose=1, save_best_only=True, save_weights_only=True, \n",
    "                                              mode='auto', period=1),\n",
    "\n",
    "    keras.callbacks.TensorBoard(log_dir='/tmp/log', histogram_freq=0, write_graph=True, update_freq='epoch', write_images=True),\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yS2K9F5aFH_4"
   },
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kXYjqTxnFH_5",
    "outputId": "389b9859-4597-4255-f62a-92be083b3833",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 15 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 364s 21s/step - loss: 1.0224 - accuracy: 0.4945 - recall: 0.4897 - val_loss: 0.6138 - val_accuracy: 0.8438 - val_recall: 0.9545\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.02242, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/20000\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.7387 - accuracy: 0.6820 - recall: 0.8011 - val_loss: 0.7229 - val_accuracy: 0.6875 - val_recall: 0.9500\n",
      "\n",
      "Epoch 00002: loss improved from 1.02242 to 0.73869, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 3/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.5666 - accuracy: 0.7886 - recall: 0.6921 - val_loss: 0.5334 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00003: loss improved from 0.73869 to 0.56665, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 4/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.5120 - accuracy: 0.8309 - recall: 0.8224 - val_loss: 0.3160 - val_accuracy: 0.9062 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00004: loss improved from 0.56665 to 0.51201, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 5/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4815 - accuracy: 0.8493 - recall: 0.8363 - val_loss: 0.4441 - val_accuracy: 0.8750 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00005: loss improved from 0.51201 to 0.48151, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 6/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4879 - accuracy: 0.8272 - recall: 0.7900 - val_loss: 0.3073 - val_accuracy: 0.9062 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.48151\n",
      "Epoch 7/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4494 - accuracy: 0.8621 - recall: 0.8145 - val_loss: 0.3614 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00007: loss improved from 0.48151 to 0.44938, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 8/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4552 - accuracy: 0.8529 - recall: 0.8373 - val_loss: 0.4495 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.44938\n",
      "Epoch 9/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4520 - accuracy: 0.8401 - recall: 0.8036 - val_loss: 0.2960 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.44938\n",
      "Epoch 10/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4342 - accuracy: 0.8456 - recall: 0.8380 - val_loss: 0.3283 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00010: loss improved from 0.44938 to 0.43416, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 11/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4046 - accuracy: 0.8768 - recall: 0.8403 - val_loss: 0.1782 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00011: loss improved from 0.43416 to 0.40460, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 12/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4007 - accuracy: 0.8805 - recall: 0.8327 - val_loss: 0.2928 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00012: loss improved from 0.40460 to 0.40069, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 13/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4209 - accuracy: 0.8805 - recall: 0.8556 - val_loss: 0.3529 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.40069\n",
      "Epoch 14/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3931 - accuracy: 0.8787 - recall: 0.8445 - val_loss: 0.2818 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00014: loss improved from 0.40069 to 0.39306, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 15/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4073 - accuracy: 0.8732 - recall: 0.8689 - val_loss: 0.2319 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.39306\n",
      "Epoch 16/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4068 - accuracy: 0.8640 - recall: 0.8170 - val_loss: 0.2532 - val_accuracy: 0.9375 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.39306\n",
      "Epoch 17/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3807 - accuracy: 0.8787 - recall: 0.8493 - val_loss: 0.2345 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00017: loss improved from 0.39306 to 0.38071, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 18/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3871 - accuracy: 0.8768 - recall: 0.8486 - val_loss: 0.2265 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.38071\n",
      "Epoch 19/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3953 - accuracy: 0.8695 - recall: 0.8348 - val_loss: 0.2299 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.38071\n",
      "Epoch 20/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3795 - accuracy: 0.8860 - recall: 0.8573 - val_loss: 0.1430 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00020: loss improved from 0.38071 to 0.37955, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 21/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3601 - accuracy: 0.8915 - recall: 0.8611 - val_loss: 0.2516 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00021: loss improved from 0.37955 to 0.36010, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 22/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3495 - accuracy: 0.9044 - recall: 0.8870 - val_loss: 0.2600 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00022: loss improved from 0.36010 to 0.34954, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 23/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3589 - accuracy: 0.9007 - recall: 0.8918 - val_loss: 0.2327 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.34954\n",
      "Epoch 24/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3752 - accuracy: 0.8676 - recall: 0.8245 - val_loss: 0.1838 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.34954\n",
      "Epoch 25/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3627 - accuracy: 0.8879 - recall: 0.8528 - val_loss: 0.1866 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.34954\n",
      "Epoch 26/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3903 - accuracy: 0.8658 - recall: 0.8358 - val_loss: 0.2046 - val_accuracy: 0.9688 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.34954\n",
      "Epoch 27/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3819 - accuracy: 0.8621 - recall: 0.8223 - val_loss: 0.1805 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.34954\n",
      "Epoch 28/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3375 - accuracy: 0.8934 - recall: 0.8675 - val_loss: 0.1768 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00028: loss improved from 0.34954 to 0.33749, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 29/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3493 - accuracy: 0.8897 - recall: 0.8729 - val_loss: 0.2254 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.33749\n",
      "Epoch 30/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3376 - accuracy: 0.8915 - recall: 0.8664 - val_loss: 0.1831 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.33749\n",
      "Epoch 31/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3484 - accuracy: 0.8824 - recall: 0.8687 - val_loss: 0.2116 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.33749\n",
      "Epoch 32/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3533 - accuracy: 0.8989 - recall: 0.8664 - val_loss: 0.2142 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.33749\n",
      "Epoch 33/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3480 - accuracy: 0.8860 - recall: 0.8731 - val_loss: 0.1858 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.33749\n",
      "Epoch 34/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3373 - accuracy: 0.8934 - recall: 0.8548 - val_loss: 0.2217 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00034: loss improved from 0.33749 to 0.33734, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 35/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3524 - accuracy: 0.8879 - recall: 0.8708 - val_loss: 0.2309 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.33734\n",
      "Epoch 36/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3587 - accuracy: 0.8787 - recall: 0.8790 - val_loss: 0.2207 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.33734\n",
      "Epoch 37/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3328 - accuracy: 0.9026 - recall: 0.8635 - val_loss: 0.1708 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00037: loss improved from 0.33734 to 0.33275, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 38/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3262 - accuracy: 0.9118 - recall: 0.8655 - val_loss: 0.1829 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00038: loss improved from 0.33275 to 0.32618, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 39/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3354 - accuracy: 0.8897 - recall: 0.8837 - val_loss: 0.2480 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.32618\n",
      "Epoch 40/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3616 - accuracy: 0.8732 - recall: 0.8376 - val_loss: 0.1980 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.32618\n",
      "Epoch 41/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3536 - accuracy: 0.8879 - recall: 0.8497 - val_loss: 0.2027 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.32618\n",
      "Epoch 42/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3450 - accuracy: 0.8915 - recall: 0.8595 - val_loss: 0.1767 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.32618\n",
      "Epoch 43/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3465 - accuracy: 0.8768 - recall: 0.8511 - val_loss: 0.1991 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.32618\n",
      "Epoch 44/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3392 - accuracy: 0.8879 - recall: 0.8730 - val_loss: 0.1238 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.32618\n",
      "Epoch 45/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3346 - accuracy: 0.8989 - recall: 0.8742 - val_loss: 0.1346 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.32618\n",
      "Epoch 46/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3287 - accuracy: 0.8989 - recall: 0.8941 - val_loss: 0.1984 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.32618\n",
      "Epoch 47/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3506 - accuracy: 0.8805 - recall: 0.8362 - val_loss: 0.1892 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.32618\n",
      "Epoch 48/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3340 - accuracy: 0.8952 - recall: 0.8633 - val_loss: 0.1795 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.099900001488626.\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.32618\n",
      "Epoch 49/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3381 - accuracy: 0.8915 - recall: 0.8514 - val_loss: 0.1074 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.32618\n",
      "Epoch 50/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3294 - accuracy: 0.9026 - recall: 0.8770 - val_loss: 0.1565 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.32618\n",
      "Epoch 51/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3415 - accuracy: 0.8934 - recall: 0.8698 - val_loss: 0.1557 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.32618\n",
      "Epoch 52/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3249 - accuracy: 0.8952 - recall: 0.8689 - val_loss: 0.1506 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00052: loss improved from 0.32618 to 0.32489, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 53/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3150 - accuracy: 0.9044 - recall: 0.8738 - val_loss: 0.1532 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00053: loss improved from 0.32489 to 0.31497, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 54/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3202 - accuracy: 0.9007 - recall: 0.8484 - val_loss: 0.1553 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.31497\n",
      "Epoch 55/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3360 - accuracy: 0.8879 - recall: 0.8646 - val_loss: 0.1374 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.31497\n",
      "Epoch 56/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3342 - accuracy: 0.8934 - recall: 0.8670 - val_loss: 0.1966 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.31497\n",
      "Epoch 57/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3106 - accuracy: 0.8934 - recall: 0.8810 - val_loss: 0.1735 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00057: loss improved from 0.31497 to 0.31059, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 58/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3166 - accuracy: 0.9081 - recall: 0.8932 - val_loss: 0.1474 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.31059\n",
      "Epoch 59/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3153 - accuracy: 0.9136 - recall: 0.8842 - val_loss: 0.1614 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.31059\n",
      "Epoch 60/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3373 - accuracy: 0.8897 - recall: 0.8828 - val_loss: 0.1884 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.31059\n",
      "Epoch 61/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3253 - accuracy: 0.9007 - recall: 0.8605 - val_loss: 0.1308 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.31059\n",
      "Epoch 62/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3162 - accuracy: 0.8989 - recall: 0.8720 - val_loss: 0.1980 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.31059\n",
      "Epoch 63/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3399 - accuracy: 0.8842 - recall: 0.8224 - val_loss: 0.1202 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.31059\n",
      "Epoch 64/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3325 - accuracy: 0.9118 - recall: 0.8955 - val_loss: 0.1156 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.31059\n",
      "Epoch 65/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3208 - accuracy: 0.9007 - recall: 0.8961 - val_loss: 0.1997 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.31059\n",
      "Epoch 66/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3303 - accuracy: 0.8915 - recall: 0.8797 - val_loss: 0.1610 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.31059\n",
      "Epoch 67/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3099 - accuracy: 0.9099 - recall: 0.8942 - val_loss: 0.1293 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00067: loss improved from 0.31059 to 0.30989, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 68/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3163 - accuracy: 0.9044 - recall: 0.8755 - val_loss: 0.1877 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.30989\n",
      "Epoch 69/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2973 - accuracy: 0.9062 - recall: 0.8845 - val_loss: 0.1896 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00069: loss improved from 0.30989 to 0.29732, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 70/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3291 - accuracy: 0.8971 - recall: 0.8868 - val_loss: 0.1242 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.29732\n",
      "Epoch 71/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3448 - accuracy: 0.8768 - recall: 0.8354 - val_loss: 0.1747 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.29732\n",
      "Epoch 72/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3066 - accuracy: 0.9081 - recall: 0.8926 - val_loss: 0.1511 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00072: loss did not improve from 0.29732\n",
      "Epoch 73/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3225 - accuracy: 0.8934 - recall: 0.8705 - val_loss: 0.1447 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.29732\n",
      "Epoch 74/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3172 - accuracy: 0.8879 - recall: 0.8720 - val_loss: 0.1706 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.29732\n",
      "Epoch 75/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3226 - accuracy: 0.8934 - recall: 0.8735 - val_loss: 0.1274 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.29732\n",
      "Epoch 76/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3079 - accuracy: 0.9118 - recall: 0.8922 - val_loss: 0.1137 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.29732\n",
      "Epoch 77/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3409 - accuracy: 0.8787 - recall: 0.8616 - val_loss: 0.1339 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.29732\n",
      "Epoch 78/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3201 - accuracy: 0.8989 - recall: 0.8564 - val_loss: 0.1633 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.29732\n",
      "Epoch 79/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3121 - accuracy: 0.9044 - recall: 0.8917 - val_loss: 0.1407 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.09980009979754687.\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.29732\n",
      "Epoch 80/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3113 - accuracy: 0.8915 - recall: 0.8557 - val_loss: 0.1603 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.29732\n",
      "Epoch 81/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3222 - accuracy: 0.8915 - recall: 0.8550 - val_loss: 0.0975 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.29732\n",
      "Epoch 82/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2884 - accuracy: 0.9210 - recall: 0.8911 - val_loss: 0.1939 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00082: loss improved from 0.29732 to 0.28838, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 83/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3194 - accuracy: 0.8952 - recall: 0.8724 - val_loss: 0.1861 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.28838\n",
      "Epoch 84/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3194 - accuracy: 0.8971 - recall: 0.8736 - val_loss: 0.1509 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.28838\n",
      "Epoch 85/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3317 - accuracy: 0.8842 - recall: 0.8776 - val_loss: 0.1351 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.28838\n",
      "Epoch 86/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3148 - accuracy: 0.9154 - recall: 0.8955 - val_loss: 0.1317 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.28838\n",
      "Epoch 87/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2794 - accuracy: 0.9338 - recall: 0.9075 - val_loss: 0.1426 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00087: loss improved from 0.28838 to 0.27939, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 88/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2897 - accuracy: 0.9191 - recall: 0.8888 - val_loss: 0.1617 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.27939\n",
      "Epoch 89/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3021 - accuracy: 0.9026 - recall: 0.8785 - val_loss: 0.1312 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.27939\n",
      "Epoch 90/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3016 - accuracy: 0.9191 - recall: 0.8899 - val_loss: 0.1652 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00090: loss did not improve from 0.27939\n",
      "Epoch 91/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2950 - accuracy: 0.9026 - recall: 0.8728 - val_loss: 0.1550 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.27939\n",
      "Epoch 92/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3017 - accuracy: 0.9081 - recall: 0.8718 - val_loss: 0.1691 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.27939\n",
      "Epoch 93/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3029 - accuracy: 0.9062 - recall: 0.8856 - val_loss: 0.1693 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.27939\n",
      "Epoch 94/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3093 - accuracy: 0.8934 - recall: 0.8903 - val_loss: 0.1709 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.27939\n",
      "Epoch 95/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2884 - accuracy: 0.9154 - recall: 0.8909 - val_loss: 0.1535 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.27939\n",
      "Epoch 96/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3025 - accuracy: 0.9007 - recall: 0.8782 - val_loss: 0.1689 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.27939\n",
      "Epoch 97/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3102 - accuracy: 0.8897 - recall: 0.8592 - val_loss: 0.0939 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.09970030231028795.\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.27939\n",
      "Epoch 98/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2895 - accuracy: 0.9118 - recall: 0.8785 - val_loss: 0.1377 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.27939\n",
      "Epoch 99/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2988 - accuracy: 0.9154 - recall: 0.8822 - val_loss: 0.1411 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.27939\n",
      "Epoch 100/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3240 - accuracy: 0.8952 - recall: 0.8768 - val_loss: 0.1309 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00100: loss did not improve from 0.27939\n",
      "Epoch 101/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2865 - accuracy: 0.9246 - recall: 0.9048 - val_loss: 0.1320 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00101: loss did not improve from 0.27939\n",
      "Epoch 102/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2831 - accuracy: 0.9136 - recall: 0.9142 - val_loss: 0.1767 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00102: loss did not improve from 0.27939\n",
      "Epoch 103/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2960 - accuracy: 0.9081 - recall: 0.8800 - val_loss: 0.1569 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00103: loss did not improve from 0.27939\n",
      "Epoch 104/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3025 - accuracy: 0.9062 - recall: 0.8943 - val_loss: 0.1356 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00104: loss did not improve from 0.27939\n",
      "Epoch 105/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2731 - accuracy: 0.9191 - recall: 0.8947 - val_loss: 0.1373 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00105: loss improved from 0.27939 to 0.27312, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 106/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2750 - accuracy: 0.9265 - recall: 0.8926 - val_loss: 0.1322 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00106: loss did not improve from 0.27312\n",
      "Epoch 107/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3009 - accuracy: 0.8971 - recall: 0.8738 - val_loss: 0.1177 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00107: loss did not improve from 0.27312\n",
      "Epoch 108/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2902 - accuracy: 0.9246 - recall: 0.9008 - val_loss: 0.1105 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00108: loss did not improve from 0.27312\n",
      "Epoch 109/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2770 - accuracy: 0.9154 - recall: 0.9032 - val_loss: 0.1022 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00109: loss did not improve from 0.27312\n",
      "Epoch 110/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3036 - accuracy: 0.9081 - recall: 0.8944 - val_loss: 0.1472 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00110: loss did not improve from 0.27312\n",
      "Epoch 111/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2952 - accuracy: 0.9099 - recall: 0.8885 - val_loss: 0.1157 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00111: loss did not improve from 0.27312\n",
      "Epoch 112/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2973 - accuracy: 0.8934 - recall: 0.8629 - val_loss: 0.1531 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00112: loss did not improve from 0.27312\n",
      "Epoch 113/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3006 - accuracy: 0.9154 - recall: 0.8917 - val_loss: 0.1546 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00113: loss did not improve from 0.27312\n",
      "Epoch 114/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2885 - accuracy: 0.9154 - recall: 0.8841 - val_loss: 0.1410 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00114: loss did not improve from 0.27312\n",
      "Epoch 115/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2894 - accuracy: 0.9118 - recall: 0.8921 - val_loss: 0.1728 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.09960060158371925.\n",
      "\n",
      "Epoch 00115: loss did not improve from 0.27312\n",
      "Epoch 116/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2766 - accuracy: 0.8952 - recall: 0.8835 - val_loss: 0.1634 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00116: loss did not improve from 0.27312\n",
      "Epoch 117/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2926 - accuracy: 0.9210 - recall: 0.8931 - val_loss: 0.1396 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00117: loss did not improve from 0.27312\n",
      "Epoch 118/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2919 - accuracy: 0.9099 - recall: 0.8523 - val_loss: 0.1454 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00118: loss did not improve from 0.27312\n",
      "Epoch 119/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2992 - accuracy: 0.8897 - recall: 0.8631 - val_loss: 0.1362 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00119: loss did not improve from 0.27312\n",
      "Epoch 120/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2701 - accuracy: 0.9099 - recall: 0.8759 - val_loss: 0.1870 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00120: loss improved from 0.27312 to 0.27009, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 121/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2846 - accuracy: 0.9191 - recall: 0.8877 - val_loss: 0.0988 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00121: loss did not improve from 0.27009\n",
      "Epoch 122/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2880 - accuracy: 0.9026 - recall: 0.8834 - val_loss: 0.1300 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00122: loss did not improve from 0.27009\n",
      "Epoch 123/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3282 - accuracy: 0.8915 - recall: 0.8667 - val_loss: 0.1216 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00123: loss did not improve from 0.27009\n",
      "Epoch 124/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2748 - accuracy: 0.9191 - recall: 0.9169 - val_loss: 0.1354 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00124: loss did not improve from 0.27009\n",
      "Epoch 125/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2839 - accuracy: 0.9191 - recall: 0.9078 - val_loss: 0.1528 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00125: loss did not improve from 0.27009\n",
      "Epoch 126/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2993 - accuracy: 0.8934 - recall: 0.9156 - val_loss: 0.1479 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00126: loss did not improve from 0.27009\n",
      "Epoch 127/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2840 - accuracy: 0.9118 - recall: 0.9096 - val_loss: 0.1253 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00127: loss did not improve from 0.27009\n",
      "Epoch 128/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2864 - accuracy: 0.9191 - recall: 0.8939 - val_loss: 0.1145 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00128: loss did not improve from 0.27009\n",
      "Epoch 129/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2814 - accuracy: 0.9136 - recall: 0.8875 - val_loss: 0.1592 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00129: loss did not improve from 0.27009\n",
      "Epoch 130/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2854 - accuracy: 0.9228 - recall: 0.9205 - val_loss: 0.1249 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 0.09950099761784077.\n",
      "\n",
      "Epoch 00130: loss did not improve from 0.27009\n",
      "Epoch 131/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2897 - accuracy: 0.9191 - recall: 0.8681 - val_loss: 0.1654 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00131: loss did not improve from 0.27009\n",
      "Epoch 132/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2716 - accuracy: 0.9210 - recall: 0.8912 - val_loss: 0.1461 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00132: loss did not improve from 0.27009\n",
      "Epoch 133/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2831 - accuracy: 0.9173 - recall: 0.8591 - val_loss: 0.1605 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00133: loss did not improve from 0.27009\n",
      "Epoch 134/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2913 - accuracy: 0.9007 - recall: 0.8805 - val_loss: 0.1431 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00134: loss did not improve from 0.27009\n",
      "Epoch 135/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2775 - accuracy: 0.9136 - recall: 0.9050 - val_loss: 0.1061 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00135: loss did not improve from 0.27009\n",
      "Epoch 136/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2817 - accuracy: 0.9154 - recall: 0.8913 - val_loss: 0.1070 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00136: loss did not improve from 0.27009\n",
      "Epoch 137/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2766 - accuracy: 0.9191 - recall: 0.8827 - val_loss: 0.1070 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00137: loss did not improve from 0.27009\n",
      "Epoch 138/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2962 - accuracy: 0.9154 - recall: 0.9049 - val_loss: 0.1195 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00138: loss did not improve from 0.27009\n",
      "Epoch 139/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2966 - accuracy: 0.9081 - recall: 0.8775 - val_loss: 0.1361 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00139: loss did not improve from 0.27009\n",
      "Epoch 140/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2883 - accuracy: 0.9118 - recall: 0.8960 - val_loss: 0.1067 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 0.0994014978557825.\n",
      "\n",
      "Epoch 00140: loss did not improve from 0.27009\n",
      "Epoch 141/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2711 - accuracy: 0.9265 - recall: 0.8945 - val_loss: 0.0979 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00141: loss did not improve from 0.27009\n",
      "Epoch 142/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2880 - accuracy: 0.9081 - recall: 0.9010 - val_loss: 0.1290 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00142: loss did not improve from 0.27009\n",
      "Epoch 143/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2621 - accuracy: 0.9191 - recall: 0.8856 - val_loss: 0.1693 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00143: loss improved from 0.27009 to 0.26209, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 144/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2599 - accuracy: 0.9246 - recall: 0.9070 - val_loss: 0.1848 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00144: loss improved from 0.26209 to 0.25990, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 145/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2914 - accuracy: 0.9062 - recall: 0.8742 - val_loss: 0.1894 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00145: loss did not improve from 0.25990\n",
      "Epoch 146/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2679 - accuracy: 0.9265 - recall: 0.9038 - val_loss: 0.0962 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00146: loss did not improve from 0.25990\n",
      "Epoch 147/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2791 - accuracy: 0.9154 - recall: 0.8948 - val_loss: 0.1775 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00147: loss did not improve from 0.25990\n",
      "Epoch 148/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2875 - accuracy: 0.9081 - recall: 0.9010 - val_loss: 0.1636 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00148: loss did not improve from 0.25990\n",
      "Epoch 149/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2782 - accuracy: 0.9044 - recall: 0.8736 - val_loss: 0.1648 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00149: loss did not improve from 0.25990\n",
      "Epoch 150/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2443 - accuracy: 0.9301 - recall: 0.9107 - val_loss: 0.1089 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00150: loss improved from 0.25990 to 0.24427, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 151/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3107 - accuracy: 0.8989 - recall: 0.8700 - val_loss: 0.1129 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00151: loss did not improve from 0.24427\n",
      "Epoch 152/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2640 - accuracy: 0.9210 - recall: 0.9154 - val_loss: 0.1455 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00152: loss did not improve from 0.24427\n",
      "Epoch 153/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2671 - accuracy: 0.9375 - recall: 0.9366 - val_loss: 0.1055 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00153: loss did not improve from 0.24427\n",
      "Epoch 154/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2832 - accuracy: 0.9154 - recall: 0.8803 - val_loss: 0.1353 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00154: loss did not improve from 0.24427\n",
      "Epoch 155/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2754 - accuracy: 0.9210 - recall: 0.8881 - val_loss: 0.1328 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00155: loss did not improve from 0.24427\n",
      "Epoch 156/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2744 - accuracy: 0.9136 - recall: 0.8880 - val_loss: 0.1362 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00156: loss did not improve from 0.24427\n",
      "Epoch 157/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2942 - accuracy: 0.9044 - recall: 0.8876 - val_loss: 0.1048 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00157: loss did not improve from 0.24427\n",
      "Epoch 158/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2656 - accuracy: 0.9228 - recall: 0.8988 - val_loss: 0.1234 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00158: loss did not improve from 0.24427\n",
      "Epoch 159/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2808 - accuracy: 0.9099 - recall: 0.8864 - val_loss: 0.1676 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00159: loss did not improve from 0.24427\n",
      "Epoch 160/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2767 - accuracy: 0.9191 - recall: 0.9211 - val_loss: 0.1050 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.09930209485441446.\n",
      "\n",
      "Epoch 00160: loss did not improve from 0.24427\n",
      "Epoch 161/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2497 - accuracy: 0.9375 - recall: 0.9380 - val_loss: 0.1385 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00161: loss did not improve from 0.24427\n",
      "Epoch 162/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2929 - accuracy: 0.9007 - recall: 0.8577 - val_loss: 0.1219 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00162: loss did not improve from 0.24427\n",
      "Epoch 163/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2765 - accuracy: 0.9191 - recall: 0.9031 - val_loss: 0.1504 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00163: loss did not improve from 0.24427\n",
      "Epoch 164/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2618 - accuracy: 0.9283 - recall: 0.9211 - val_loss: 0.1430 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00164: loss did not improve from 0.24427\n",
      "Epoch 165/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2834 - accuracy: 0.9118 - recall: 0.9019 - val_loss: 0.1123 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00165: loss did not improve from 0.24427\n",
      "Epoch 166/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2790 - accuracy: 0.9044 - recall: 0.8885 - val_loss: 0.1336 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00166: loss did not improve from 0.24427\n",
      "Epoch 167/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2579 - accuracy: 0.9246 - recall: 0.9144 - val_loss: 0.1545 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00167: loss did not improve from 0.24427\n",
      "Epoch 168/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2758 - accuracy: 0.9228 - recall: 0.8998 - val_loss: 0.1128 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00168: loss did not improve from 0.24427\n",
      "Epoch 169/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2913 - accuracy: 0.8989 - recall: 0.9120 - val_loss: 0.1308 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00169: loss did not improve from 0.24427\n",
      "Epoch 170/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2659 - accuracy: 0.9246 - recall: 0.9007 - val_loss: 0.1096 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.09920279605686665.\n",
      "\n",
      "Epoch 00170: loss did not improve from 0.24427\n",
      "Epoch 171/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2862 - accuracy: 0.9007 - recall: 0.8702 - val_loss: 0.1253 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00171: loss did not improve from 0.24427\n",
      "Epoch 172/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2762 - accuracy: 0.9173 - recall: 0.9103 - val_loss: 0.1364 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00172: loss did not improve from 0.24427\n",
      "Epoch 173/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2746 - accuracy: 0.9265 - recall: 0.9096 - val_loss: 0.1117 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00173: loss did not improve from 0.24427\n",
      "Epoch 174/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2972 - accuracy: 0.9007 - recall: 0.8643 - val_loss: 0.1271 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00174: loss did not improve from 0.24427\n",
      "Epoch 175/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2672 - accuracy: 0.9191 - recall: 0.9067 - val_loss: 0.1253 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00175: loss did not improve from 0.24427\n",
      "Epoch 176/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2711 - accuracy: 0.9191 - recall: 0.9037 - val_loss: 0.1151 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00176: loss did not improve from 0.24427\n",
      "Epoch 177/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2793 - accuracy: 0.9136 - recall: 0.8878 - val_loss: 0.1356 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00177: loss did not improve from 0.24427\n",
      "Epoch 178/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2489 - accuracy: 0.9228 - recall: 0.9169 - val_loss: 0.0857 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00178: loss did not improve from 0.24427\n",
      "Epoch 179/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2659 - accuracy: 0.9173 - recall: 0.8795 - val_loss: 0.1510 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00179: loss did not improve from 0.24427\n",
      "Epoch 180/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2857 - accuracy: 0.9044 - recall: 0.8769 - val_loss: 0.1221 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 0.09910359402000904.\n",
      "\n",
      "Epoch 00180: loss did not improve from 0.24427\n",
      "Epoch 181/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2938 - accuracy: 0.9154 - recall: 0.8983 - val_loss: 0.1229 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00181: loss did not improve from 0.24427\n",
      "Epoch 182/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2557 - accuracy: 0.9210 - recall: 0.8632 - val_loss: 0.1521 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00182: loss did not improve from 0.24427\n",
      "Epoch 183/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2827 - accuracy: 0.9136 - recall: 0.8788 - val_loss: 0.1131 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00183: loss did not improve from 0.24427\n",
      "Epoch 184/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2515 - accuracy: 0.9210 - recall: 0.9316 - val_loss: 0.1373 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00184: loss did not improve from 0.24427\n",
      "Epoch 185/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2625 - accuracy: 0.9265 - recall: 0.9043 - val_loss: 0.1119 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00185: loss did not improve from 0.24427\n",
      "Epoch 186/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2613 - accuracy: 0.9301 - recall: 0.9059 - val_loss: 0.1511 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00186: loss did not improve from 0.24427\n",
      "Epoch 187/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2747 - accuracy: 0.9173 - recall: 0.8872 - val_loss: 0.1360 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00187: loss did not improve from 0.24427\n",
      "Epoch 188/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2676 - accuracy: 0.9228 - recall: 0.9071 - val_loss: 0.1197 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00188: loss did not improve from 0.24427\n",
      "Epoch 189/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2703 - accuracy: 0.9118 - recall: 0.8898 - val_loss: 0.1233 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00189: loss did not improve from 0.24427\n",
      "Epoch 190/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2900 - accuracy: 0.9026 - recall: 0.8742 - val_loss: 0.1264 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 0.09900448874384164.\n",
      "\n",
      "Epoch 00190: loss did not improve from 0.24427\n",
      "Epoch 191/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2710 - accuracy: 0.9136 - recall: 0.9043 - val_loss: 0.1307 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00191: loss did not improve from 0.24427\n",
      "Epoch 192/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2761 - accuracy: 0.9283 - recall: 0.8863 - val_loss: 0.1060 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00192: loss did not improve from 0.24427\n",
      "Epoch 193/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2705 - accuracy: 0.9265 - recall: 0.9140 - val_loss: 0.1316 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00193: loss did not improve from 0.24427\n",
      "Epoch 194/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2893 - accuracy: 0.9044 - recall: 0.8959 - val_loss: 0.1154 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00194: loss did not improve from 0.24427\n",
      "Epoch 195/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2652 - accuracy: 0.9118 - recall: 0.8868 - val_loss: 0.1254 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00195: loss did not improve from 0.24427\n",
      "Epoch 196/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2507 - accuracy: 0.9467 - recall: 0.9305 - val_loss: 0.1329 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00196: loss did not improve from 0.24427\n",
      "Epoch 197/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2617 - accuracy: 0.9246 - recall: 0.8878 - val_loss: 0.1083 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00197: loss did not improve from 0.24427\n",
      "Epoch 198/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2732 - accuracy: 0.9210 - recall: 0.9033 - val_loss: 0.0963 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00198: loss did not improve from 0.24427\n",
      "Epoch 199/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2565 - accuracy: 0.9375 - recall: 0.9122 - val_loss: 0.1003 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00199: loss did not improve from 0.24427\n",
      "Epoch 200/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2933 - accuracy: 0.8971 - recall: 0.8602 - val_loss: 0.0877 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 0.09890548767149449.\n",
      "\n",
      "Epoch 00200: loss did not improve from 0.24427\n",
      "Epoch 201/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2850 - accuracy: 0.9062 - recall: 0.8896 - val_loss: 0.1493 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00201: loss did not improve from 0.24427\n",
      "Epoch 202/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2549 - accuracy: 0.9228 - recall: 0.9217 - val_loss: 0.1316 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00202: loss did not improve from 0.24427\n",
      "Epoch 203/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2938 - accuracy: 0.9026 - recall: 0.9071 - val_loss: 0.1153 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00203: loss did not improve from 0.24427\n",
      "Epoch 204/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2752 - accuracy: 0.9210 - recall: 0.8832 - val_loss: 0.1475 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00204: loss did not improve from 0.24427\n",
      "Epoch 205/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2575 - accuracy: 0.9173 - recall: 0.9041 - val_loss: 0.1434 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00205: loss did not improve from 0.24427\n",
      "Epoch 206/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2823 - accuracy: 0.9154 - recall: 0.8908 - val_loss: 0.1313 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00206: loss did not improve from 0.24427\n",
      "Epoch 207/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2640 - accuracy: 0.9136 - recall: 0.8590 - val_loss: 0.1204 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00207: loss did not improve from 0.24427\n",
      "Epoch 208/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3061 - accuracy: 0.8952 - recall: 0.8676 - val_loss: 0.1331 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00208: loss did not improve from 0.24427\n",
      "Epoch 209/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2744 - accuracy: 0.9210 - recall: 0.9220 - val_loss: 0.1240 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00209: loss did not improve from 0.24427\n",
      "Epoch 210/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2776 - accuracy: 0.9044 - recall: 0.8721 - val_loss: 0.1207 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 0.09880658335983754.\n",
      "\n",
      "Epoch 00210: loss did not improve from 0.24427\n",
      "Epoch 211/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2633 - accuracy: 0.9246 - recall: 0.9001 - val_loss: 0.1204 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00211: loss did not improve from 0.24427\n",
      "Epoch 212/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2712 - accuracy: 0.9210 - recall: 0.9075 - val_loss: 0.1403 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00212: loss did not improve from 0.24427\n",
      "Epoch 213/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2854 - accuracy: 0.9118 - recall: 0.9114 - val_loss: 0.1178 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00213: loss did not improve from 0.24427\n",
      "Epoch 214/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2689 - accuracy: 0.9210 - recall: 0.9002 - val_loss: 0.1101 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00214: loss did not improve from 0.24427\n",
      "Epoch 215/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2533 - accuracy: 0.9246 - recall: 0.8882 - val_loss: 0.1444 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00215: loss did not improve from 0.24427\n",
      "Epoch 216/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2567 - accuracy: 0.9154 - recall: 0.8963 - val_loss: 0.0743 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00216: loss did not improve from 0.24427\n",
      "Epoch 217/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2693 - accuracy: 0.9210 - recall: 0.8966 - val_loss: 0.0878 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00217: loss did not improve from 0.24427\n",
      "Epoch 218/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2804 - accuracy: 0.9191 - recall: 0.9046 - val_loss: 0.1157 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00218: loss did not improve from 0.24427\n",
      "Epoch 219/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2653 - accuracy: 0.9265 - recall: 0.8867 - val_loss: 0.1121 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00219: loss did not improve from 0.24427\n",
      "Epoch 220/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2695 - accuracy: 0.9265 - recall: 0.8883 - val_loss: 0.1114 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 0.09870777580887079.\n",
      "\n",
      "Epoch 00220: loss did not improve from 0.24427\n",
      "Epoch 221/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2827 - accuracy: 0.9154 - recall: 0.9175 - val_loss: 0.1455 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00221: loss did not improve from 0.24427\n",
      "Epoch 222/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2936 - accuracy: 0.9154 - recall: 0.9221 - val_loss: 0.1265 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00222: loss did not improve from 0.24427\n",
      "Epoch 223/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2639 - accuracy: 0.9412 - recall: 0.9259 - val_loss: 0.1129 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00223: loss did not improve from 0.24427\n",
      "Epoch 224/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2608 - accuracy: 0.9173 - recall: 0.9048 - val_loss: 0.0816 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00224: loss did not improve from 0.24427\n",
      "Epoch 225/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2805 - accuracy: 0.9136 - recall: 0.8719 - val_loss: 0.0764 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00225: loss did not improve from 0.24427\n",
      "Epoch 226/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2737 - accuracy: 0.9173 - recall: 0.8747 - val_loss: 0.0992 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00226: loss did not improve from 0.24427\n",
      "Epoch 227/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2724 - accuracy: 0.9173 - recall: 0.9141 - val_loss: 0.1022 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00227: loss did not improve from 0.24427\n",
      "Epoch 228/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2646 - accuracy: 0.9191 - recall: 0.8904 - val_loss: 0.1179 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00228: loss did not improve from 0.24427\n",
      "Epoch 229/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2633 - accuracy: 0.9191 - recall: 0.9027 - val_loss: 0.1428 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00229: loss did not improve from 0.24427\n",
      "Epoch 230/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2794 - accuracy: 0.9191 - recall: 0.9001 - val_loss: 0.1154 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 0.09860906501859426.\n",
      "\n",
      "Epoch 00230: loss did not improve from 0.24427\n",
      "Epoch 231/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2613 - accuracy: 0.9301 - recall: 0.9175 - val_loss: 0.1204 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00231: loss did not improve from 0.24427\n",
      "Epoch 232/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2712 - accuracy: 0.9081 - recall: 0.8796 - val_loss: 0.1375 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00232: loss did not improve from 0.24427\n",
      "Epoch 233/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2687 - accuracy: 0.9191 - recall: 0.8974 - val_loss: 0.1431 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00233: loss did not improve from 0.24427\n",
      "Epoch 234/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2816 - accuracy: 0.9173 - recall: 0.9050 - val_loss: 0.1526 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00234: loss did not improve from 0.24427\n",
      "Epoch 235/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2837 - accuracy: 0.9210 - recall: 0.8910 - val_loss: 0.1053 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00235: loss did not improve from 0.24427\n",
      "Epoch 236/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2682 - accuracy: 0.9246 - recall: 0.8847 - val_loss: 0.1207 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00236: loss did not improve from 0.24427\n",
      "Epoch 237/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2799 - accuracy: 0.9173 - recall: 0.8993 - val_loss: 0.0889 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00237: loss did not improve from 0.24427\n",
      "Epoch 238/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2771 - accuracy: 0.9099 - recall: 0.8954 - val_loss: 0.1640 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00238: loss did not improve from 0.24427\n",
      "Epoch 239/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2457 - accuracy: 0.9265 - recall: 0.8825 - val_loss: 0.1375 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00239: loss did not improve from 0.24427\n",
      "Epoch 240/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2822 - accuracy: 0.8989 - recall: 0.8607 - val_loss: 0.1234 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 0.09851045843213796.\n",
      "\n",
      "Epoch 00240: loss did not improve from 0.24427\n",
      "Epoch 241/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2531 - accuracy: 0.9246 - recall: 0.8960 - val_loss: 0.0943 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00241: loss did not improve from 0.24427\n",
      "Epoch 242/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2913 - accuracy: 0.9118 - recall: 0.8758 - val_loss: 0.1265 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00242: loss did not improve from 0.24427\n",
      "Epoch 243/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2623 - accuracy: 0.9210 - recall: 0.8806 - val_loss: 0.0997 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00243: loss did not improve from 0.24427\n",
      "Epoch 244/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2681 - accuracy: 0.9081 - recall: 0.8825 - val_loss: 0.0824 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00244: loss did not improve from 0.24427\n",
      "Epoch 245/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2669 - accuracy: 0.9246 - recall: 0.9040 - val_loss: 0.1297 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00245: loss did not improve from 0.24427\n",
      "Epoch 246/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2614 - accuracy: 0.9210 - recall: 0.9140 - val_loss: 0.1370 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00246: loss did not improve from 0.24427\n",
      "Epoch 247/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3021 - accuracy: 0.9026 - recall: 0.8976 - val_loss: 0.1210 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00247: loss did not improve from 0.24427\n",
      "Epoch 248/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2453 - accuracy: 0.9265 - recall: 0.8943 - val_loss: 0.1384 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00248: loss did not improve from 0.24427\n",
      "Epoch 249/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2778 - accuracy: 0.9062 - recall: 0.8729 - val_loss: 0.1301 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00249: loss did not improve from 0.24427\n",
      "Epoch 250/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2591 - accuracy: 0.9062 - recall: 0.9026 - val_loss: 0.1060 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00250: ReduceLROnPlateau reducing learning rate to 0.09841194860637188.\n",
      "\n",
      "Epoch 00250: loss did not improve from 0.24427\n",
      "Epoch 251/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2829 - accuracy: 0.9062 - recall: 0.8764 - val_loss: 0.1186 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00251: loss did not improve from 0.24427\n",
      "Epoch 252/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2685 - accuracy: 0.9099 - recall: 0.8929 - val_loss: 0.0752 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00252: loss did not improve from 0.24427\n",
      "Epoch 253/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2542 - accuracy: 0.9283 - recall: 0.9197 - val_loss: 0.1409 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00253: loss did not improve from 0.24427\n",
      "Epoch 254/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2538 - accuracy: 0.9265 - recall: 0.9081 - val_loss: 0.1243 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00254: loss did not improve from 0.24427\n",
      "Epoch 255/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2469 - accuracy: 0.9320 - recall: 0.9343 - val_loss: 0.1334 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00255: loss did not improve from 0.24427\n",
      "Epoch 256/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2709 - accuracy: 0.9118 - recall: 0.8774 - val_loss: 0.1055 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00256: loss did not improve from 0.24427\n",
      "Epoch 257/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2518 - accuracy: 0.9228 - recall: 0.8939 - val_loss: 0.1323 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00257: loss did not improve from 0.24427\n",
      "Epoch 258/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2987 - accuracy: 0.9044 - recall: 0.8706 - val_loss: 0.0921 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00258: loss did not improve from 0.24427\n",
      "Epoch 259/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2695 - accuracy: 0.9191 - recall: 0.8850 - val_loss: 0.1437 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00259: loss did not improve from 0.24427\n",
      "Epoch 260/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2660 - accuracy: 0.9320 - recall: 0.9129 - val_loss: 0.1113 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00260: ReduceLROnPlateau reducing learning rate to 0.098313535541296.\n",
      "\n",
      "Epoch 00260: loss did not improve from 0.24427\n",
      "Epoch 261/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2849 - accuracy: 0.9044 - recall: 0.8964 - val_loss: 0.1038 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00261: loss did not improve from 0.24427\n",
      "Epoch 262/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2609 - accuracy: 0.9246 - recall: 0.8899 - val_loss: 0.1471 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00262: loss did not improve from 0.24427\n",
      "Epoch 263/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2651 - accuracy: 0.9099 - recall: 0.9099 - val_loss: 0.0994 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00263: loss did not improve from 0.24427\n",
      "Epoch 264/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2857 - accuracy: 0.9099 - recall: 0.8996 - val_loss: 0.1147 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00264: loss did not improve from 0.24427\n",
      "Epoch 265/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2827 - accuracy: 0.9062 - recall: 0.8779 - val_loss: 0.1025 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00265: loss did not improve from 0.24427\n",
      "Epoch 266/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2400 - accuracy: 0.9228 - recall: 0.9012 - val_loss: 0.0657 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00266: loss improved from 0.24427 to 0.24002, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 267/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2665 - accuracy: 0.9228 - recall: 0.9047 - val_loss: 0.0989 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00267: loss did not improve from 0.24002\n",
      "Epoch 268/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2648 - accuracy: 0.9099 - recall: 0.8584 - val_loss: 0.1092 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00268: loss did not improve from 0.24002\n",
      "Epoch 269/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2820 - accuracy: 0.9081 - recall: 0.8977 - val_loss: 0.0530 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00269: loss did not improve from 0.24002\n",
      "Epoch 270/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2522 - accuracy: 0.9320 - recall: 0.9194 - val_loss: 0.1142 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00270: loss did not improve from 0.24002\n",
      "Epoch 271/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2575 - accuracy: 0.9191 - recall: 0.8886 - val_loss: 0.1311 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00271: loss did not improve from 0.24002\n",
      "Epoch 272/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2567 - accuracy: 0.9173 - recall: 0.8792 - val_loss: 0.1206 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00272: loss did not improve from 0.24002\n",
      "Epoch 273/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2538 - accuracy: 0.9393 - recall: 0.8962 - val_loss: 0.1303 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00273: loss did not improve from 0.24002\n",
      "Epoch 274/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2737 - accuracy: 0.9118 - recall: 0.8927 - val_loss: 0.1028 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00274: loss did not improve from 0.24002\n",
      "Epoch 275/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2646 - accuracy: 0.9265 - recall: 0.9011 - val_loss: 0.1440 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00275: loss did not improve from 0.24002\n",
      "Epoch 276/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2761 - accuracy: 0.9246 - recall: 0.9227 - val_loss: 0.1375 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00276: ReduceLROnPlateau reducing learning rate to 0.09821521923691034.\n",
      "\n",
      "Epoch 00276: loss did not improve from 0.24002\n",
      "Epoch 277/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2718 - accuracy: 0.9099 - recall: 0.8611 - val_loss: 0.0967 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00277: loss did not improve from 0.24002\n",
      "Epoch 278/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2697 - accuracy: 0.9283 - recall: 0.8844 - val_loss: 0.1030 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00278: loss did not improve from 0.24002\n",
      "Epoch 279/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2320 - accuracy: 0.9357 - recall: 0.9333 - val_loss: 0.0880 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00279: loss improved from 0.24002 to 0.23203, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 280/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2576 - accuracy: 0.9210 - recall: 0.9127 - val_loss: 0.1018 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00280: loss did not improve from 0.23203\n",
      "Epoch 281/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2486 - accuracy: 0.9393 - recall: 0.9286 - val_loss: 0.1459 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00281: loss did not improve from 0.23203\n",
      "Epoch 282/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2503 - accuracy: 0.9154 - recall: 0.8973 - val_loss: 0.1526 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00282: loss did not improve from 0.23203\n",
      "Epoch 283/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2756 - accuracy: 0.9210 - recall: 0.9085 - val_loss: 0.0889 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00283: loss did not improve from 0.23203\n",
      "Epoch 284/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2647 - accuracy: 0.9136 - recall: 0.9188 - val_loss: 0.1310 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00284: loss did not improve from 0.23203\n",
      "Epoch 285/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2554 - accuracy: 0.9265 - recall: 0.9076 - val_loss: 0.1394 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00285: loss did not improve from 0.23203\n",
      "Epoch 286/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2700 - accuracy: 0.9154 - recall: 0.8835 - val_loss: 0.1273 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00286: loss did not improve from 0.23203\n",
      "Epoch 287/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2508 - accuracy: 0.9338 - recall: 0.8974 - val_loss: 0.1248 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00287: loss did not improve from 0.23203\n",
      "Epoch 288/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2402 - accuracy: 0.9154 - recall: 0.9053 - val_loss: 0.1048 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00288: loss did not improve from 0.23203\n",
      "Epoch 289/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2499 - accuracy: 0.9338 - recall: 0.8969 - val_loss: 0.0834 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 0.09811700713634491.\n",
      "\n",
      "Epoch 00289: loss did not improve from 0.23203\n",
      "Epoch 290/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2600 - accuracy: 0.9246 - recall: 0.9049 - val_loss: 0.0879 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00290: loss did not improve from 0.23203\n",
      "Epoch 291/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2544 - accuracy: 0.9210 - recall: 0.9204 - val_loss: 0.1351 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00291: loss did not improve from 0.23203\n",
      "Epoch 292/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2555 - accuracy: 0.9228 - recall: 0.8821 - val_loss: 0.1471 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00292: loss did not improve from 0.23203\n",
      "Epoch 293/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2483 - accuracy: 0.9283 - recall: 0.9066 - val_loss: 0.0990 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00293: loss did not improve from 0.23203\n",
      "Epoch 294/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2311 - accuracy: 0.9357 - recall: 0.9176 - val_loss: 0.0960 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00294: loss improved from 0.23203 to 0.23106, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 295/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2329 - accuracy: 0.9412 - recall: 0.9024 - val_loss: 0.1183 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00295: loss did not improve from 0.23106\n",
      "Epoch 296/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2619 - accuracy: 0.9246 - recall: 0.9010 - val_loss: 0.1268 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00296: loss did not improve from 0.23106\n",
      "Epoch 297/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2687 - accuracy: 0.9173 - recall: 0.9021 - val_loss: 0.1071 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00297: loss did not improve from 0.23106\n",
      "Epoch 298/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2447 - accuracy: 0.9357 - recall: 0.9110 - val_loss: 0.1232 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00298: loss did not improve from 0.23106\n",
      "Epoch 299/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2655 - accuracy: 0.9338 - recall: 0.9228 - val_loss: 0.1000 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00299: loss did not improve from 0.23106\n",
      "Epoch 300/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2511 - accuracy: 0.9246 - recall: 0.8944 - val_loss: 0.0945 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00300: loss did not improve from 0.23106\n",
      "Epoch 301/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2491 - accuracy: 0.9228 - recall: 0.9091 - val_loss: 0.0961 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00301: loss did not improve from 0.23106\n",
      "Epoch 302/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2511 - accuracy: 0.9191 - recall: 0.9244 - val_loss: 0.0835 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00302: loss did not improve from 0.23106\n",
      "Epoch 303/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2583 - accuracy: 0.9320 - recall: 0.9089 - val_loss: 0.1340 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00303: loss did not improve from 0.23106\n",
      "Epoch 304/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2660 - accuracy: 0.9283 - recall: 0.9172 - val_loss: 0.1287 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00304: ReduceLROnPlateau reducing learning rate to 0.09801889179646969.\n",
      "\n",
      "Epoch 00304: loss did not improve from 0.23106\n",
      "Epoch 305/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2515 - accuracy: 0.9283 - recall: 0.9102 - val_loss: 0.1138 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00305: loss did not improve from 0.23106\n",
      "Epoch 306/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2613 - accuracy: 0.9320 - recall: 0.9268 - val_loss: 0.0970 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00306: loss did not improve from 0.23106\n",
      "Epoch 307/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2671 - accuracy: 0.9136 - recall: 0.8882 - val_loss: 0.1175 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00307: loss did not improve from 0.23106\n",
      "Epoch 308/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2658 - accuracy: 0.9026 - recall: 0.8695 - val_loss: 0.1185 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00308: loss did not improve from 0.23106\n",
      "Epoch 309/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2418 - accuracy: 0.9375 - recall: 0.9126 - val_loss: 0.0838 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00309: loss did not improve from 0.23106\n",
      "Epoch 310/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2549 - accuracy: 0.9191 - recall: 0.8788 - val_loss: 0.0866 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00310: loss did not improve from 0.23106\n",
      "Epoch 311/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2329 - accuracy: 0.9449 - recall: 0.9219 - val_loss: 0.1133 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00311: loss did not improve from 0.23106\n",
      "Epoch 312/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2510 - accuracy: 0.9357 - recall: 0.9461 - val_loss: 0.0949 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00312: loss did not improve from 0.23106\n",
      "Epoch 313/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2370 - accuracy: 0.9375 - recall: 0.9245 - val_loss: 0.1158 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00313: loss did not improve from 0.23106\n",
      "Epoch 314/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2664 - accuracy: 0.9246 - recall: 0.9204 - val_loss: 0.0847 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00314: ReduceLROnPlateau reducing learning rate to 0.09792087321728468.\n",
      "\n",
      "Epoch 00314: loss did not improve from 0.23106\n",
      "Epoch 315/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2473 - accuracy: 0.9246 - recall: 0.9156 - val_loss: 0.1044 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00315: loss did not improve from 0.23106\n",
      "Epoch 316/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2436 - accuracy: 0.9246 - recall: 0.9030 - val_loss: 0.0946 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00316: loss did not improve from 0.23106\n",
      "Epoch 317/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2598 - accuracy: 0.9301 - recall: 0.9272 - val_loss: 0.1242 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00317: loss did not improve from 0.23106\n",
      "Epoch 318/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2662 - accuracy: 0.9173 - recall: 0.8909 - val_loss: 0.1284 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00318: loss did not improve from 0.23106\n",
      "Epoch 319/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2327 - accuracy: 0.9393 - recall: 0.9372 - val_loss: 0.1296 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00319: loss did not improve from 0.23106\n",
      "Epoch 320/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2375 - accuracy: 0.9393 - recall: 0.8924 - val_loss: 0.0798 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00320: loss did not improve from 0.23106\n",
      "Epoch 321/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2592 - accuracy: 0.9301 - recall: 0.9132 - val_loss: 0.1231 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00321: loss did not improve from 0.23106\n",
      "Epoch 322/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2724 - accuracy: 0.9118 - recall: 0.8849 - val_loss: 0.0951 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00322: loss did not improve from 0.23106\n",
      "Epoch 323/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2383 - accuracy: 0.9338 - recall: 0.8958 - val_loss: 0.0663 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00323: loss did not improve from 0.23106\n",
      "Epoch 324/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2389 - accuracy: 0.9375 - recall: 0.9058 - val_loss: 0.0999 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 0.09782295139878988.\n",
      "\n",
      "Epoch 00324: loss did not improve from 0.23106\n",
      "Epoch 325/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2678 - accuracy: 0.9173 - recall: 0.8965 - val_loss: 0.0879 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00325: loss did not improve from 0.23106\n",
      "Epoch 326/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2706 - accuracy: 0.9081 - recall: 0.8914 - val_loss: 0.0864 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00326: loss did not improve from 0.23106\n",
      "Epoch 327/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2444 - accuracy: 0.9283 - recall: 0.8869 - val_loss: 0.0866 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00327: loss did not improve from 0.23106\n",
      "Epoch 328/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2572 - accuracy: 0.9173 - recall: 0.8675 - val_loss: 0.1060 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00328: loss did not improve from 0.23106\n",
      "Epoch 329/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2463 - accuracy: 0.9301 - recall: 0.9027 - val_loss: 0.1057 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00329: loss did not improve from 0.23106\n",
      "Epoch 330/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2659 - accuracy: 0.9118 - recall: 0.8814 - val_loss: 0.0975 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00330: loss did not improve from 0.23106\n",
      "Epoch 331/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2532 - accuracy: 0.9118 - recall: 0.8925 - val_loss: 0.0734 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00331: loss did not improve from 0.23106\n",
      "Epoch 332/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2401 - accuracy: 0.9412 - recall: 0.9161 - val_loss: 0.0996 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00332: loss did not improve from 0.23106\n",
      "Epoch 333/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2568 - accuracy: 0.9118 - recall: 0.8982 - val_loss: 0.1135 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00333: loss did not improve from 0.23106\n",
      "Epoch 334/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2528 - accuracy: 0.9320 - recall: 0.9249 - val_loss: 0.0992 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00334: ReduceLROnPlateau reducing learning rate to 0.0977251263409853.\n",
      "\n",
      "Epoch 00334: loss did not improve from 0.23106\n",
      "Epoch 335/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2717 - accuracy: 0.9173 - recall: 0.8971 - val_loss: 0.1153 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00335: loss did not improve from 0.23106\n",
      "Epoch 336/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2461 - accuracy: 0.9265 - recall: 0.9097 - val_loss: 0.0846 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00336: loss did not improve from 0.23106\n",
      "Epoch 337/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2680 - accuracy: 0.9081 - recall: 0.8865 - val_loss: 0.0691 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00337: loss did not improve from 0.23106\n",
      "Epoch 338/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2598 - accuracy: 0.9118 - recall: 0.8999 - val_loss: 0.0887 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00338: loss did not improve from 0.23106\n",
      "Epoch 339/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2551 - accuracy: 0.9265 - recall: 0.9103 - val_loss: 0.1237 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00339: loss did not improve from 0.23106\n",
      "Epoch 340/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2638 - accuracy: 0.9228 - recall: 0.8754 - val_loss: 0.1092 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00340: loss did not improve from 0.23106\n",
      "Epoch 341/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2781 - accuracy: 0.9118 - recall: 0.9071 - val_loss: 0.1133 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00341: loss did not improve from 0.23106\n",
      "Epoch 342/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2457 - accuracy: 0.9246 - recall: 0.9195 - val_loss: 0.0666 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00342: loss did not improve from 0.23106\n",
      "Epoch 343/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2448 - accuracy: 0.9412 - recall: 0.9340 - val_loss: 0.0760 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00343: loss did not improve from 0.23106\n",
      "Epoch 344/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2584 - accuracy: 0.9136 - recall: 0.8969 - val_loss: 0.1115 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00344: ReduceLROnPlateau reducing learning rate to 0.09762739804387092.\n",
      "\n",
      "Epoch 00344: loss did not improve from 0.23106\n",
      "Epoch 345/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2698 - accuracy: 0.9081 - recall: 0.8754 - val_loss: 0.0709 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00345: loss did not improve from 0.23106\n",
      "Epoch 346/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2517 - accuracy: 0.9283 - recall: 0.8941 - val_loss: 0.1306 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00346: loss did not improve from 0.23106\n",
      "Epoch 347/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2584 - accuracy: 0.9246 - recall: 0.9044 - val_loss: 0.0974 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00347: loss did not improve from 0.23106\n",
      "Epoch 348/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2553 - accuracy: 0.9173 - recall: 0.9109 - val_loss: 0.0869 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00348: loss did not improve from 0.23106\n",
      "Epoch 349/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2368 - accuracy: 0.9301 - recall: 0.9034 - val_loss: 0.1359 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00349: loss did not improve from 0.23106\n",
      "Epoch 350/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2798 - accuracy: 0.9099 - recall: 0.8707 - val_loss: 0.0911 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00350: loss did not improve from 0.23106\n",
      "Epoch 351/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2288 - accuracy: 0.9430 - recall: 0.9278 - val_loss: 0.0979 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00351: loss improved from 0.23106 to 0.22879, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 352/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2340 - accuracy: 0.9375 - recall: 0.9244 - val_loss: 0.1319 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00352: loss did not improve from 0.22879\n",
      "Epoch 353/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2460 - accuracy: 0.9228 - recall: 0.8787 - val_loss: 0.1361 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00353: loss did not improve from 0.22879\n",
      "Epoch 354/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2665 - accuracy: 0.9265 - recall: 0.9134 - val_loss: 0.1062 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00354: loss did not improve from 0.22879\n",
      "Epoch 355/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2470 - accuracy: 0.9301 - recall: 0.9156 - val_loss: 0.0904 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00355: loss did not improve from 0.22879\n",
      "Epoch 356/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2567 - accuracy: 0.9210 - recall: 0.8831 - val_loss: 0.1066 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00356: loss did not improve from 0.22879\n",
      "Epoch 357/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2327 - accuracy: 0.9338 - recall: 0.8935 - val_loss: 0.0861 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00357: loss did not improve from 0.22879\n",
      "Epoch 358/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2269 - accuracy: 0.9412 - recall: 0.9300 - val_loss: 0.0745 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00358: loss improved from 0.22879 to 0.22687, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 359/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2498 - accuracy: 0.9246 - recall: 0.8961 - val_loss: 0.1070 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00359: loss did not improve from 0.22687\n",
      "Epoch 360/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2479 - accuracy: 0.9338 - recall: 0.9159 - val_loss: 0.0793 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00360: loss did not improve from 0.22687\n",
      "Epoch 361/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2474 - accuracy: 0.9246 - recall: 0.9212 - val_loss: 0.1237 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00361: loss did not improve from 0.22687\n",
      "Epoch 362/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2575 - accuracy: 0.9191 - recall: 0.8829 - val_loss: 0.0816 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00362: loss did not improve from 0.22687\n",
      "Epoch 363/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2565 - accuracy: 0.9118 - recall: 0.9215 - val_loss: 0.1358 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00363: loss did not improve from 0.22687\n",
      "Epoch 364/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2596 - accuracy: 0.9136 - recall: 0.8969 - val_loss: 0.1129 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00364: loss did not improve from 0.22687\n",
      "Epoch 365/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2591 - accuracy: 0.9210 - recall: 0.9162 - val_loss: 0.1394 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00365: loss did not improve from 0.22687\n",
      "Epoch 366/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2370 - accuracy: 0.9301 - recall: 0.9284 - val_loss: 0.0973 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00366: loss did not improve from 0.22687\n",
      "Epoch 367/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2388 - accuracy: 0.9283 - recall: 0.9071 - val_loss: 0.0936 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00367: loss did not improve from 0.22687\n",
      "Epoch 368/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2488 - accuracy: 0.9265 - recall: 0.9133 - val_loss: 0.0631 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00368: ReduceLROnPlateau reducing learning rate to 0.09752977395057678.\n",
      "\n",
      "Epoch 00368: loss did not improve from 0.22687\n",
      "Epoch 369/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2487 - accuracy: 0.9412 - recall: 0.9288 - val_loss: 0.0992 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00369: loss did not improve from 0.22687\n",
      "Epoch 370/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2666 - accuracy: 0.9228 - recall: 0.9133 - val_loss: 0.0909 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00370: loss did not improve from 0.22687\n",
      "Epoch 371/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2380 - accuracy: 0.9375 - recall: 0.9178 - val_loss: 0.0949 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00371: loss did not improve from 0.22687\n",
      "Epoch 372/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2474 - accuracy: 0.9191 - recall: 0.8920 - val_loss: 0.1116 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00372: loss did not improve from 0.22687\n",
      "Epoch 373/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2460 - accuracy: 0.9320 - recall: 0.9106 - val_loss: 0.0981 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00373: loss did not improve from 0.22687\n",
      "Epoch 374/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2539 - accuracy: 0.9210 - recall: 0.9070 - val_loss: 0.0955 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00374: loss did not improve from 0.22687\n",
      "Epoch 375/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2702 - accuracy: 0.9154 - recall: 0.8848 - val_loss: 0.0919 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00375: loss did not improve from 0.22687\n",
      "Epoch 376/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2420 - accuracy: 0.9320 - recall: 0.9037 - val_loss: 0.0852 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00376: loss did not improve from 0.22687\n",
      "Epoch 377/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2710 - accuracy: 0.9136 - recall: 0.9013 - val_loss: 0.1037 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00377: loss did not improve from 0.22687\n",
      "Epoch 378/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2745 - accuracy: 0.9099 - recall: 0.8887 - val_loss: 0.1156 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00378: ReduceLROnPlateau reducing learning rate to 0.09743224661797285.\n",
      "\n",
      "Epoch 00378: loss did not improve from 0.22687\n",
      "Epoch 379/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2656 - accuracy: 0.9191 - recall: 0.9051 - val_loss: 0.1214 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00379: loss did not improve from 0.22687\n",
      "Epoch 380/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2432 - accuracy: 0.9320 - recall: 0.9432 - val_loss: 0.1134 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00380: loss did not improve from 0.22687\n",
      "Epoch 381/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2540 - accuracy: 0.9265 - recall: 0.9103 - val_loss: 0.0756 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00381: loss did not improve from 0.22687\n",
      "Epoch 382/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2496 - accuracy: 0.9283 - recall: 0.9122 - val_loss: 0.0982 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00382: loss did not improve from 0.22687\n",
      "Epoch 383/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2557 - accuracy: 0.9210 - recall: 0.8934 - val_loss: 0.0921 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00383: loss did not improve from 0.22687\n",
      "Epoch 384/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2542 - accuracy: 0.9393 - recall: 0.9350 - val_loss: 0.1269 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00384: loss did not improve from 0.22687\n",
      "Epoch 385/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2318 - accuracy: 0.9393 - recall: 0.9275 - val_loss: 0.0769 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00385: loss did not improve from 0.22687\n",
      "Epoch 386/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2485 - accuracy: 0.9191 - recall: 0.9009 - val_loss: 0.1177 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00386: loss did not improve from 0.22687\n",
      "Epoch 387/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2314 - accuracy: 0.9375 - recall: 0.9308 - val_loss: 0.0854 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00387: loss did not improve from 0.22687\n",
      "Epoch 388/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2576 - accuracy: 0.9173 - recall: 0.8966 - val_loss: 0.0965 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00388: ReduceLROnPlateau reducing learning rate to 0.09733481604605913.\n",
      "\n",
      "Epoch 00388: loss did not improve from 0.22687\n",
      "Epoch 389/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2487 - accuracy: 0.9357 - recall: 0.9280 - val_loss: 0.1108 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00389: loss did not improve from 0.22687\n",
      "Epoch 390/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2523 - accuracy: 0.9228 - recall: 0.9025 - val_loss: 0.0888 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00390: loss did not improve from 0.22687\n",
      "Epoch 391/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2641 - accuracy: 0.9154 - recall: 0.8982 - val_loss: 0.0760 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00391: loss did not improve from 0.22687\n",
      "Epoch 392/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2456 - accuracy: 0.9228 - recall: 0.9173 - val_loss: 0.1178 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00392: loss did not improve from 0.22687\n",
      "Epoch 393/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2626 - accuracy: 0.9099 - recall: 0.8862 - val_loss: 0.0878 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00393: loss did not improve from 0.22687\n",
      "Epoch 394/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2494 - accuracy: 0.9283 - recall: 0.8983 - val_loss: 0.1234 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00394: loss did not improve from 0.22687\n",
      "Epoch 395/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2317 - accuracy: 0.9412 - recall: 0.9154 - val_loss: 0.0830 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00395: loss did not improve from 0.22687\n",
      "Epoch 396/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2315 - accuracy: 0.9283 - recall: 0.9050 - val_loss: 0.0624 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00396: loss did not improve from 0.22687\n",
      "Epoch 397/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2428 - accuracy: 0.9412 - recall: 0.9278 - val_loss: 0.1426 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00397: loss did not improve from 0.22687\n",
      "Epoch 398/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2457 - accuracy: 0.9173 - recall: 0.9010 - val_loss: 0.1044 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00398: ReduceLROnPlateau reducing learning rate to 0.09723748223483562.\n",
      "\n",
      "Epoch 00398: loss did not improve from 0.22687\n",
      "Epoch 399/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2410 - accuracy: 0.9338 - recall: 0.9379 - val_loss: 0.1350 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00399: loss did not improve from 0.22687\n",
      "Epoch 400/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2508 - accuracy: 0.9246 - recall: 0.9264 - val_loss: 0.1148 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00400: loss did not improve from 0.22687\n",
      "Epoch 401/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2536 - accuracy: 0.9246 - recall: 0.9205 - val_loss: 0.1109 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00401: loss did not improve from 0.22687\n",
      "Epoch 402/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2616 - accuracy: 0.9191 - recall: 0.9061 - val_loss: 0.0888 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00402: loss did not improve from 0.22687\n",
      "Epoch 403/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2643 - accuracy: 0.9301 - recall: 0.9202 - val_loss: 0.1441 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00403: loss did not improve from 0.22687\n",
      "Epoch 404/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2206 - accuracy: 0.9320 - recall: 0.8941 - val_loss: 0.1270 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00404: loss improved from 0.22687 to 0.22061, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 405/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2359 - accuracy: 0.9375 - recall: 0.9135 - val_loss: 0.1377 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00405: loss did not improve from 0.22061\n",
      "Epoch 406/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2312 - accuracy: 0.9301 - recall: 0.9151 - val_loss: 0.1424 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00406: loss did not improve from 0.22061\n",
      "Epoch 407/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2429 - accuracy: 0.9246 - recall: 0.8948 - val_loss: 0.1134 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00407: loss did not improve from 0.22061\n",
      "Epoch 408/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2639 - accuracy: 0.9081 - recall: 0.9231 - val_loss: 0.0869 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00408: loss did not improve from 0.22061\n",
      "Epoch 409/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2445 - accuracy: 0.9210 - recall: 0.8886 - val_loss: 0.1403 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00409: loss did not improve from 0.22061\n",
      "Epoch 410/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2331 - accuracy: 0.9393 - recall: 0.9180 - val_loss: 0.0981 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00410: loss did not improve from 0.22061\n",
      "Epoch 411/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2440 - accuracy: 0.9393 - recall: 0.9389 - val_loss: 0.0774 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00411: loss did not improve from 0.22061\n",
      "Epoch 412/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2523 - accuracy: 0.9265 - recall: 0.9167 - val_loss: 0.1044 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00412: loss did not improve from 0.22061\n",
      "Epoch 413/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2323 - accuracy: 0.9338 - recall: 0.9347 - val_loss: 0.0922 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00413: loss did not improve from 0.22061\n",
      "Epoch 414/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2365 - accuracy: 0.9228 - recall: 0.8841 - val_loss: 0.0899 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00414: ReduceLROnPlateau reducing learning rate to 0.09714024518430232.\n",
      "\n",
      "Epoch 00414: loss did not improve from 0.22061\n",
      "Epoch 415/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2386 - accuracy: 0.9338 - recall: 0.9077 - val_loss: 0.1307 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00415: loss did not improve from 0.22061\n",
      "Epoch 416/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2376 - accuracy: 0.9357 - recall: 0.9142 - val_loss: 0.1039 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00416: loss did not improve from 0.22061\n",
      "Epoch 417/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2386 - accuracy: 0.9338 - recall: 0.9249 - val_loss: 0.1227 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00417: loss did not improve from 0.22061\n",
      "Epoch 418/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2399 - accuracy: 0.9338 - recall: 0.9153 - val_loss: 0.0877 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00418: loss did not improve from 0.22061\n",
      "Epoch 419/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2819 - accuracy: 0.9062 - recall: 0.8660 - val_loss: 0.0780 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00419: loss did not improve from 0.22061\n",
      "Epoch 420/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2275 - accuracy: 0.9338 - recall: 0.9199 - val_loss: 0.0987 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00420: loss did not improve from 0.22061\n",
      "Epoch 421/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2615 - accuracy: 0.9320 - recall: 0.9178 - val_loss: 0.0794 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00421: loss did not improve from 0.22061\n",
      "Epoch 422/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2240 - accuracy: 0.9393 - recall: 0.9297 - val_loss: 0.1382 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00422: loss did not improve from 0.22061\n",
      "Epoch 423/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2656 - accuracy: 0.9191 - recall: 0.8979 - val_loss: 0.1243 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00423: loss did not improve from 0.22061\n",
      "Epoch 424/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2582 - accuracy: 0.9191 - recall: 0.9182 - val_loss: 0.0852 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00424: ReduceLROnPlateau reducing learning rate to 0.09704310489445925.\n",
      "\n",
      "Epoch 00424: loss did not improve from 0.22061\n",
      "Epoch 425/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2411 - accuracy: 0.9393 - recall: 0.9173 - val_loss: 0.0827 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00425: loss did not improve from 0.22061\n",
      "Epoch 426/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2529 - accuracy: 0.9210 - recall: 0.8966 - val_loss: 0.1065 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00426: loss did not improve from 0.22061\n",
      "Epoch 427/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2573 - accuracy: 0.9099 - recall: 0.8977 - val_loss: 0.1213 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00427: loss did not improve from 0.22061\n",
      "Epoch 428/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2611 - accuracy: 0.9265 - recall: 0.9092 - val_loss: 0.1049 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00428: loss did not improve from 0.22061\n",
      "Epoch 429/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2528 - accuracy: 0.9265 - recall: 0.9154 - val_loss: 0.1281 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00429: loss did not improve from 0.22061\n",
      "Epoch 430/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2573 - accuracy: 0.9191 - recall: 0.9039 - val_loss: 0.0780 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00430: loss did not improve from 0.22061\n",
      "Epoch 431/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2459 - accuracy: 0.9246 - recall: 0.9112 - val_loss: 0.1329 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00431: loss did not improve from 0.22061\n",
      "Epoch 432/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2408 - accuracy: 0.9412 - recall: 0.9275 - val_loss: 0.1013 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00432: loss did not improve from 0.22061\n",
      "Epoch 433/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2598 - accuracy: 0.9118 - recall: 0.8810 - val_loss: 0.1065 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00433: loss did not improve from 0.22061\n",
      "Epoch 434/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2485 - accuracy: 0.9283 - recall: 0.9042 - val_loss: 0.0980 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00434: ReduceLROnPlateau reducing learning rate to 0.09694606136530638.\n",
      "\n",
      "Epoch 00434: loss did not improve from 0.22061\n",
      "Epoch 435/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2458 - accuracy: 0.9210 - recall: 0.8959 - val_loss: 0.1113 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00435: loss did not improve from 0.22061\n",
      "Epoch 436/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2210 - accuracy: 0.9467 - recall: 0.9328 - val_loss: 0.1001 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00436: loss did not improve from 0.22061\n",
      "Epoch 437/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2458 - accuracy: 0.9265 - recall: 0.9015 - val_loss: 0.1009 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00437: loss did not improve from 0.22061\n",
      "Epoch 438/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2534 - accuracy: 0.9210 - recall: 0.8798 - val_loss: 0.1287 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00438: loss did not improve from 0.22061\n",
      "Epoch 439/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2291 - accuracy: 0.9412 - recall: 0.9421 - val_loss: 0.1123 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00439: loss did not improve from 0.22061\n",
      "Epoch 440/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2577 - accuracy: 0.9301 - recall: 0.9325 - val_loss: 0.0977 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00440: loss did not improve from 0.22061\n",
      "Epoch 441/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2344 - accuracy: 0.9430 - recall: 0.9356 - val_loss: 0.0943 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00441: loss did not improve from 0.22061\n",
      "Epoch 442/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2381 - accuracy: 0.9393 - recall: 0.9130 - val_loss: 0.0711 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00442: loss did not improve from 0.22061\n",
      "Epoch 443/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2078 - accuracy: 0.9522 - recall: 0.9349 - val_loss: 0.1059 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00443: loss improved from 0.22061 to 0.20781, saving model to weights_i3d_RGB_no_softmax.hdf5\n",
      "Epoch 444/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2659 - accuracy: 0.9246 - recall: 0.9065 - val_loss: 0.1230 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00444: loss did not improve from 0.20781\n",
      "Epoch 445/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2542 - accuracy: 0.9173 - recall: 0.8989 - val_loss: 0.1174 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00445: loss did not improve from 0.20781\n",
      "Epoch 446/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2256 - accuracy: 0.9504 - recall: 0.9308 - val_loss: 0.0790 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00446: loss did not improve from 0.20781\n",
      "Epoch 447/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2316 - accuracy: 0.9265 - recall: 0.8949 - val_loss: 0.0837 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00447: loss did not improve from 0.20781\n",
      "Epoch 448/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2475 - accuracy: 0.9118 - recall: 0.8800 - val_loss: 0.1196 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00448: loss did not improve from 0.20781\n",
      "Epoch 449/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2495 - accuracy: 0.9118 - recall: 0.9007 - val_loss: 0.1091 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00449: loss did not improve from 0.20781\n",
      "Epoch 450/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2355 - accuracy: 0.9210 - recall: 0.9035 - val_loss: 0.0903 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00450: loss did not improve from 0.20781\n",
      "Epoch 451/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2439 - accuracy: 0.9191 - recall: 0.8915 - val_loss: 0.0561 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00451: loss did not improve from 0.20781\n",
      "Epoch 452/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2412 - accuracy: 0.9265 - recall: 0.9156 - val_loss: 0.0736 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00452: loss did not improve from 0.20781\n",
      "Epoch 453/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2566 - accuracy: 0.9246 - recall: 0.9099 - val_loss: 0.0988 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00453: ReduceLROnPlateau reducing learning rate to 0.09684911459684371.\n",
      "\n",
      "Epoch 00453: loss did not improve from 0.20781\n",
      "Epoch 454/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2427 - accuracy: 0.9301 - recall: 0.9201 - val_loss: 0.0936 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00454: loss did not improve from 0.20781\n",
      "Epoch 455/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2338 - accuracy: 0.9320 - recall: 0.8840 - val_loss: 0.1150 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00455: loss did not improve from 0.20781\n",
      "Epoch 456/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2525 - accuracy: 0.9246 - recall: 0.8977 - val_loss: 0.1018 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00456: loss did not improve from 0.20781\n",
      "Epoch 457/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2342 - accuracy: 0.9265 - recall: 0.8949 - val_loss: 0.1166 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00457: loss did not improve from 0.20781\n",
      "Epoch 458/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2305 - accuracy: 0.9467 - recall: 0.9273 - val_loss: 0.0920 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00458: loss did not improve from 0.20781\n",
      "Epoch 459/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2450 - accuracy: 0.9136 - recall: 0.9131 - val_loss: 0.1198 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00459: loss did not improve from 0.20781\n",
      "Epoch 460/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2558 - accuracy: 0.9301 - recall: 0.9131 - val_loss: 0.0935 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00460: loss did not improve from 0.20781\n",
      "Epoch 461/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2378 - accuracy: 0.9265 - recall: 0.9047 - val_loss: 0.0704 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00461: loss did not improve from 0.20781\n",
      "Epoch 462/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2432 - accuracy: 0.9283 - recall: 0.8930 - val_loss: 0.0820 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00462: loss did not improve from 0.20781\n",
      "Epoch 463/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2421 - accuracy: 0.9393 - recall: 0.9147 - val_loss: 0.0968 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00463: ReduceLROnPlateau reducing learning rate to 0.09675226458907127.\n",
      "\n",
      "Epoch 00463: loss did not improve from 0.20781\n",
      "Epoch 464/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2346 - accuracy: 0.9393 - recall: 0.9386 - val_loss: 0.0854 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00464: loss did not improve from 0.20781\n",
      "Epoch 465/20000\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2575 - accuracy: 0.9210 - recall: 0.9045 - val_loss: 0.0706 - val_accuracy: 1.0000 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00465: loss did not improve from 0.20781\n",
      "Epoch 466/20000\n",
      " 1/17 [>.............................] - ETA: 18s - loss: 0.2938 - accuracy: 0.9062 - recall: 0.8571"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9c5787e6725c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.fit_generator(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Real_i3d_RGB_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
